{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Action-Trace Analysis - Stairways V3\n",
    "## OOS Training Results & Top 10 Checkpoint Analysis\n",
    "\n",
    "**Team B Template for Team A Customization**\n",
    "\n",
    "This notebook analyzes Phase 2 OOS training results to:\n",
    "- Rank top 10 checkpoints by ep_rew_mean (secondary: Sharpe ratio)\n",
    "- Generate required visualizations for stakeholder reporting\n",
    "- Validate success criteria: Sharpe ≥ 0.3, ep_rew_mean ≥ 0.1\n",
    "\n",
    "**Usage**: Run after Phase 2 OOS training completion (3 seeds × 50K steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for professional reports\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"📊 Phase 2 Action-Trace Analysis - Stairways V3\")\n",
    "print(\"=\" * 60)\n",
    "print(\"🎯 Team B Template - Ready for Team A Customization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 OOS Training Paths (Team A: Update these paths after training completion)\n",
    "PHASE2_PATHS = [\n",
    "    Path('../train_runs/phase2_oos_seed0'),\n",
    "    Path('../train_runs/phase2_oos_seed1'), \n",
    "    Path('../train_runs/phase2_oos_seed2')\n",
    "]\n",
    "\n",
    "# Results output directory\n",
    "RESULTS_PATH = Path('../results/phase2')\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Success criteria thresholds\n",
    "SUCCESS_CRITERIA = {\n",
    "    'oos_sharpe_min': 0.3,\n",
    "    'ep_rew_mean_min': 0.1,\n",
    "    'top_n_checkpoints': 10\n",
    "}\n",
    "\n",
    "print(f\"📁 Configured {len(PHASE2_PATHS)} Phase 2 training paths\")\n",
    "print(f\"📊 Success criteria: Sharpe ≥ {SUCCESS_CRITERIA['oos_sharpe_min']}, ep_rew_mean ≥ {SUCCESS_CRITERIA['ep_rew_mean_min']}\")\n",
    "print(f\"🏆 Will analyze top {SUCCESS_CRITERIA['top_n_checkpoints']} checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phase2_action_traces(seed_paths):\n",
    "    \"\"\"\n",
    "    Load action traces from all Phase 2 OOS runs\n",
    "    \n",
    "    Args:\n",
    "        seed_paths: List of Path objects to seed run directories\n",
    "        \n",
    "    Returns:\n",
    "        dict: {seed_id: action_trace_dataframe}\n",
    "    \"\"\"\n",
    "    action_traces = {}\n",
    "    \n",
    "    for i, seed_path in enumerate(seed_paths):\n",
    "        seed_id = f\"seed_{i}\"\n",
    "        \n",
    "        # Try multiple possible action trace file formats\n",
    "        possible_files = [\n",
    "            seed_path / 'action_traces.csv',\n",
    "            seed_path / 'action_traces.parquet',\n",
    "            seed_path / 'detailed_logs.csv'\n",
    "        ]\n",
    "        \n",
    "        loaded = False\n",
    "        for trace_file in possible_files:\n",
    "            if trace_file.exists():\n",
    "                try:\n",
    "                    if trace_file.suffix == '.parquet':\n",
    "                        df = pd.read_parquet(trace_file)\n",
    "                    else:\n",
    "                        df = pd.read_csv(trace_file)\n",
    "                    \n",
    "                    df['seed_id'] = seed_id\n",
    "                    action_traces[seed_id] = df\n",
    "                    print(f\"✅ Loaded {len(df)} action records from {seed_id}\")\n",
    "                    loaded = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Failed to load {trace_file}: {e}\")\n",
    "        \n",
    "        if not loaded:\n",
    "            print(f\"❌ No action traces found for {seed_id}\")\n",
    "            # Create sample data for template demonstration\n",
    "            print(f\"📝 Creating sample data for {seed_id}\")\n",
    "            np.random.seed(42 + i)\n",
    "            n_episodes = 50\n",
    "            n_steps_per_ep = 100\n",
    "            n_samples = n_episodes * n_steps_per_ep\n",
    "            \n",
    "            sample_df = pd.DataFrame({\n",
    "                'episode_id': np.repeat(range(n_episodes), n_steps_per_ep),\n",
    "                'step': np.tile(range(n_steps_per_ep), n_episodes),\n",
    "                'episode_reward': np.repeat(np.random.normal(0.15, 0.8, n_episodes), n_steps_per_ep),\n",
    "                'step_reward': np.random.normal(0.001, 0.05, n_samples),\n",
    "                'nvda_position': np.random.choice([-1, 0, 1], n_samples, p=[0.25, 0.5, 0.25]),\n",
    "                'msft_position': np.random.choice([-1, 0, 1], n_samples, p=[0.25, 0.5, 0.25]),\n",
    "                'step_pnl': np.random.normal(0, 25, n_samples),\n",
    "                'nvda_price': 485 + np.cumsum(np.random.normal(0, 2, n_samples)),\n",
    "                'msft_price': 412 + np.cumsum(np.random.normal(0, 1.5, n_samples)),\n",
    "                'action': np.random.randint(0, 5, n_samples),\n",
    "                'timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='1min'),\n",
    "                'seed_id': seed_id\n",
    "            })\n",
    "            action_traces[seed_id] = sample_df\n",
    "    \n",
    "    return action_traces\n",
    "\n",
    "# Load all Phase 2 action traces\n",
    "phase2_traces = load_phase2_action_traces(PHASE2_PATHS)\n",
    "print(f\"\\n📈 Total seeds loaded: {len(phase2_traces)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monitor.csv Analysis & Checkpoint Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monitor_data(seed_paths):\n",
    "    \"\"\"\n",
    "    Load monitor.csv files from all Phase 2 runs for checkpoint ranking\n",
    "    \n",
    "    Returns:\n",
    "        dict: {seed_id: monitor_dataframe}\n",
    "    \"\"\"\n",
    "    monitor_data = {}\n",
    "    \n",
    "    for i, seed_path in enumerate(seed_paths):\n",
    "        seed_id = f\"seed_{i}\"\n",
    "        monitor_file = seed_path / 'monitor.csv'\n",
    "        \n",
    "        if monitor_file.exists():\n",
    "            try:\n",
    "                # Load monitor.csv (skip comment lines starting with #)\n",
    "                df = pd.read_csv(monitor_file, comment='#')\n",
    "                df['seed_id'] = seed_id\n",
    "                monitor_data[seed_id] = df\n",
    "                print(f\"✅ Loaded {len(df)} episodes from {seed_id} monitor.csv\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to load monitor.csv for {seed_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"⚠️ No monitor.csv found for {seed_id}, creating sample data\")\n",
    "            # Create sample monitor data\n",
    "            np.random.seed(42 + i)\n",
    "            n_episodes = 50\n",
    "            sample_monitor = pd.DataFrame({\n",
    "                'r': np.random.normal(0.15, 0.8, n_episodes),  # episode rewards\n",
    "                'l': np.random.randint(60, 120, n_episodes),    # episode lengths\n",
    "                't': np.cumsum(np.random.randint(60, 120, n_episodes)),  # timestamps\n",
    "                'seed_id': seed_id\n",
    "            })\n",
    "            monitor_data[seed_id] = sample_monitor\n",
    "    \n",
    "    return monitor_data\n",
    "\n",
    "# Load monitor data\n",
    "monitor_data = load_monitor_data(PHASE2_PATHS)\n",
    "print(f\"\\n📊 Monitor data loaded for {len(monitor_data)} seeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_top10_checkpoints(monitor_data, success_criteria):\n",
    "    \"\"\"\n",
    "    Rank checkpoints by ep_rew_mean, secondary by Sharpe ratio\n",
    "    \n",
    "    Args:\n",
    "        monitor_data: Dict of monitor dataframes by seed\n",
    "        success_criteria: Dict with ranking criteria\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Ranked checkpoint results\n",
    "    \"\"\"\n",
    "    checkpoint_results = []\n",
    "    \n",
    "    for seed_id, df in monitor_data.items():\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate key metrics\n",
    "        ep_rew_mean = df['r'].mean()\n",
    "        ep_rew_std = df['r'].std()\n",
    "        ep_len_mean = df['l'].mean()\n",
    "        \n",
    "        # Calculate Sharpe ratio (episode-level returns, annualized)\n",
    "        if ep_rew_std > 0:\n",
    "            sharpe = (ep_rew_mean / ep_rew_std) * np.sqrt(252)  # Assuming daily episodes\n",
    "        else:\n",
    "            sharpe = 0\n",
    "        \n",
    "        # Success criteria checks\n",
    "        meets_sharpe = sharpe >= success_criteria['oos_sharpe_min']\n",
    "        meets_reward = ep_rew_mean >= success_criteria['ep_rew_mean_min']\n",
    "        \n",
    "        checkpoint_results.append({\n",
    "            'seed_id': seed_id,\n",
    "            'ep_rew_mean': ep_rew_mean,\n",
    "            'ep_rew_std': ep_rew_std,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'ep_len_mean': ep_len_mean,\n",
    "            'total_episodes': len(df),\n",
    "            'meets_sharpe_criteria': meets_sharpe,\n",
    "            'meets_reward_criteria': meets_reward,\n",
    "            'overall_success': meets_sharpe and meets_reward\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and rank\n",
    "    results_df = pd.DataFrame(checkpoint_results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # Primary ranking: ep_rew_mean (descending)\n",
    "        # Secondary ranking: sharpe_ratio (descending)\n",
    "        results_df = results_df.sort_values(\n",
    "            ['ep_rew_mean', 'sharpe_ratio'], \n",
    "            ascending=[False, False]\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        # Add ranking\n",
    "        results_df['rank'] = range(1, len(results_df) + 1)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Rank checkpoints\n",
    "checkpoint_rankings = rank_top10_checkpoints(monitor_data, SUCCESS_CRITERIA)\n",
    "\n",
    "print(\"\\n🏆 TOP 10 CHECKPOINT RANKINGS\")\n",
    "print(\"=\" * 80)\n",
    "if len(checkpoint_rankings) > 0:\n",
    "    top_10 = checkpoint_rankings.head(SUCCESS_CRITERIA['top_n_checkpoints'])\n",
    "    \n",
    "    for _, row in top_10.iterrows():\n",
    "        success_icon = \"✅\" if row['overall_success'] else \"❌\"\n",
    "        print(f\"{success_icon} Rank {row['rank']:2d}: {row['seed_id']} | \"\n",
    "              f\"Reward: {row['ep_rew_mean']:6.3f} | \"\n",
    "              f\"Sharpe: {row['sharpe_ratio']:6.3f} | \"\n",
    "              f\"Episodes: {row['total_episodes']:3d}\")\n",
    "    \n",
    "    # Success summary\n",
    "    successful_checkpoints = checkpoint_rankings[checkpoint_rankings['overall_success']]\n",
    "    print(f\"\\n📊 SUCCESS SUMMARY:\")\n",
    "    print(f\"   Checkpoints meeting both criteria: {len(successful_checkpoints)}/{len(checkpoint_rankings)}\")\n",
    "    print(f\"   Best ep_rew_mean: {checkpoint_rankings['ep_rew_mean'].max():.3f}\")\n",
    "    print(f\"   Best Sharpe ratio: {checkpoint_rankings['sharpe_ratio'].max():.3f}\")\n",
    "else:\n",
    "    print(\"❌ No checkpoint data available for ranking\")\n",
    "\n",
    "# Save rankings to file\n",
    "checkpoint_rankings.to_csv(RESULTS_PATH / 'top10_checkpoints.csv', index=False)\n",
    "print(f\"\\n💾 Rankings saved to: {RESULTS_PATH / 'top10_checkpoints.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Required Visualizations\n",
    "### Team A: Customize these visualization functions based on your specific data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_components_timeseries(action_traces, save_path):\n",
    "    \"\"\"\n",
    "    Time-series of reward components per episode\n",
    "    \n",
    "    Team A: Customize this function based on your reward system components\n",
    "    Expected components: pnl_reward, holding_bonus, exit_tax, smoothed_penalty\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Reward Components Time Series Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combine all seeds for analysis\n",
    "    all_traces = pd.concat(action_traces.values(), ignore_index=True)\n",
    "    \n",
    "    # Episode-level aggregation\n",
    "    episode_rewards = all_traces.groupby(['seed_id', 'episode_id']).agg({\n",
    "        'episode_reward': 'first',\n",
    "        'step_reward': 'sum',\n",
    "        'step_pnl': 'sum',\n",
    "        'step': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 1. Episode rewards over time\n",
    "    for seed_id in episode_rewards['seed_id'].unique():\n",
    "        seed_data = episode_rewards[episode_rewards['seed_id'] == seed_id]\n",
    "        axes[0,0].plot(seed_data['episode_id'], seed_data['episode_reward'], \n",
    "                      alpha=0.7, label=seed_id, linewidth=1)\n",
    "    \n",
    "    axes[0,0].set_title('Episode Rewards Over Time')\n",
    "    axes[0,0].set_xlabel('Episode ID')\n",
    "    axes[0,0].set_ylabel('Episode Reward')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cumulative P&L\n",
    "    for seed_id in episode_rewards['seed_id'].unique():\n",
    "        seed_data = episode_rewards[episode_rewards['seed_id'] == seed_id]\n",
    "        cumulative_pnl = seed_data['step_pnl'].cumsum()\n",
    "        axes[0,1].plot(seed_data['episode_id'], cumulative_pnl, \n",
    "                      alpha=0.7, label=seed_id, linewidth=2)\n",
    "    \n",
    "    axes[0,1].set_title('Cumulative P&L Over Episodes')\n",
    "    axes[0,1].set_xlabel('Episode ID')\n",
    "    axes[0,1].set_ylabel('Cumulative P&L')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Episode length distribution\n",
    "    axes[1,0].hist(episode_rewards['step'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].axvline(episode_rewards['step'].mean(), color='red', linestyle='--', \n",
    "                     label=f'Mean: {episode_rewards[\"step\"].mean():.1f}')\n",
    "    axes[1,0].set_title('Episode Length Distribution')\n",
    "    axes[1,0].set_xlabel('Episode Length (steps)')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # 4. Reward vs Episode Length scatter\n",
    "    scatter = axes[1,1].scatter(episode_rewards['step'], episode_rewards['episode_reward'], \n",
    "                               alpha=0.6, c=episode_rewards['step_pnl'], cmap='RdYlGn')\n",
    "    axes[1,1].set_title('Episode Reward vs Length (colored by P&L)')\n",
    "    axes[1,1].set_xlabel('Episode Length (steps)')\n",
    "    axes[1,1].set_ylabel('Episode Reward')\n",
    "    plt.colorbar(scatter, ax=axes[1,1], label='Total P&L')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'reward_components_timeseries.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate reward components visualization\n",
    "if phase2_traces:\n",
    "    reward_fig = plot_reward_components_timeseries(phase2_traces, RESULTS_PATH)\n",
    "    print(\"✅ Reward components time series saved\")\n",
    "else:\n",
    "    print(\"❌ No action traces available for reward analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pnl_actions_overlay(action_traces, save_path):\n",
    "    \"\"\"\n",
    "    P&L vs action overlay with trade markers on price chart\n",
    "    \n",
    "    Team A: Customize based on your action space and position tracking\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "    fig.suptitle('P&L vs Actions Overlay Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Use best performing seed for detailed analysis\n",
    "    if len(checkpoint_rankings) > 0:\n",
    "        best_seed = checkpoint_rankings.iloc[0]['seed_id']\n",
    "        trace_data = phase2_traces[best_seed]\n",
    "        print(f\"📊 Analyzing best performing seed: {best_seed}\")\n",
    "    else:\n",
    "        # Use first available seed\n",
    "        best_seed = list(phase2_traces.keys())[0]\n",
    "        trace_data = phase2_traces[best_seed]\n",
    "        print(f\"📊 Analyzing seed: {best_seed}\")\n",
    "    \n",
    "    # Select a representative episode for detailed view\n",
    "    episode_rewards = trace_data.groupby('episode_id')['episode_reward'].first()\n",
    "    best_episode_id = episode_rewards.idxmax()\n",
    "    episode_data = trace_data[trace_data['episode_id'] == best_episode_id].copy()\n",
    "    episode_data = episode_data.sort_values('step')\n",
    "    \n",
    "    print(f\"📈 Analyzing best episode: {best_episode_id} (reward: {episode_rewards[best_episode_id]:.3f})\")\n",
    "    \n",
    "    # 1. NVDA Price with position markers\n",
    "    axes[0].plot(episode_data['step'], episode_data['nvda_price'], 'b-', linewidth=2, label='NVDA Price')\n",
    "    \n",
    "    # Mark position changes\n",
    "    position_changes = episode_data[episode_data['nvda_position'].diff() != 0]\n",
    "    for _, row in position_changes.iterrows():\n",
    "        color = 'green' if row['nvda_position'] > 0 else 'red' if row['nvda_position'] < 0 else 'gray'\n",
    "        marker = '^' if row['nvda_position'] > 0 else 'v' if row['nvda_position'] < 0 else 'o'\n",
    "        axes[0].scatter(row['step'], row['nvda_price'], color=color, marker=marker, s=100, alpha=0.8)\n",
    "    \n",
    "    axes[0].set_title(f'NVDA Price with Position Changes (Episode {best_episode_id})')\n",
    "    axes[0].set_ylabel('NVDA Price')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. MSFT Price with position markers\n",
    "    axes[1].plot(episode_data['step'], episode_data['msft_price'], 'r-', linewidth=2, label='MSFT Price')\n",
    "    \n",
    "    position_changes = episode_data[episode_data['msft_position'].diff() != 0]\n",
    "    for _, row in position_changes.iterrows():\n",
    "        color = 'green' if row['msft_position'] > 0 else 'red' if row['msft_position'] < 0 else 'gray'\n",
    "        marker = '^' if row['msft_position'] > 0 else 'v' if row['msft_position'] < 0 else 'o'\n",
    "        axes[1].scatter(row['step'], row['msft_price'], color=color, marker=marker, s=100, alpha=0.8)\n",
    "    \n",
    "    axes[1].set_title(f'MSFT Price with Position Changes (Episode {best_episode_id})')\n",
    "    axes[1].set_ylabel('MSFT Price')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Cumulative P&L with action markers\n",
    "    episode_data['cumulative_pnl'] = episode_data['step_pnl'].cumsum()\n",
    "    axes[2].plot(episode_data['step'], episode_data['cumulative_pnl'], 'g-', linewidth=2, label='Cumulative P&L')\n",
    "    \n",
    "    # Mark significant actions\n",
    "    action_changes = episode_data[episode_data['action'].diff() != 0]\n",
    "    for _, row in action_changes.iterrows():\n",
    "        axes[2].scatter(row['step'], row['cumulative_pnl'], color='orange', marker='D', s=60, alpha=0.7)\n",
    "    \n",
    "    axes[2].set_title(f'Cumulative P&L with Action Changes (Episode {best_episode_id})')\n",
    "    axes[2].set_xlabel('Time Step')\n",
    "    axes[2].set_ylabel('Cumulative P&L')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'pnl_actions_overlay.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate P&L vs actions overlay\n",
    "if phase2_traces:\n",
    "    pnl_fig = plot_pnl_actions_overlay(phase2_traces, RESULTS_PATH)\n",
    "    print(\"✅ P&L vs actions overlay saved\")\n",
    "else:\n",
    "    print(\"❌ No action traces available for P&L analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drawdown_holding_scatter(action_traces, save_path):\n",
    "    \"\"\"\n",
    "    Drawdown vs holding time scatter plot\n",
    "    \n",
    "    Team A: Customize based on your drawdown calculation method\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Drawdown vs Holding Time Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combine all traces for comprehensive analysis\n",
    "    all_traces = pd.concat(phase2_traces.values(), ignore_index=True)\n",
    "    \n",
    "    # Calculate episode-level metrics\n",
    "    episode_metrics = []\n",
    "    \n",
    "    for (seed_id, episode_id), episode_data in all_traces.groupby(['seed_id', 'episode_id']):\n",
    "        episode_data = episode_data.sort_values('step')\n",
    "        \n",
    "        # Calculate cumulative P&L and drawdown\n",
    "        cumulative_pnl = episode_data['step_pnl'].cumsum()\n",
    "        running_max = cumulative_pnl.expanding().max()\n",
    "        drawdown = cumulative_pnl - running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Calculate holding times for each position\n",
    "        nvda_holding_time = 0\n",
    "        msft_holding_time = 0\n",
    "        \n",
    "        # Simple holding time calculation (consecutive non-zero positions)\n",
    "        nvda_positions = episode_data['nvda_position'].values\n",
    "        msft_positions = episode_data['msft_position'].values\n",
    "        \n",
    "        # Count consecutive holding periods\n",
    "        nvda_holding_time = np.sum(nvda_positions != 0)\n",
    "        msft_holding_time = np.sum(msft_positions != 0)\n",
    "        total_holding_time = nvda_holding_time + msft_holding_time\n",
    "        \n",
    "        episode_metrics.append({\n",
    "            'seed_id': seed_id,\n",
    "            'episode_id': episode_id,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'nvda_holding_time': nvda_holding_time,\n",
    "            'msft_holding_time': msft_holding_time,\n",
    "            'total_holding_time': total_holding_time,\n",
    "            'episode_reward': episode_data['episode_reward'].iloc[0],\n",
    "            'episode_length': len(episode_data)\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(episode_metrics)\n",
    "    \n",
    "    # 1. Total holding time vs max drawdown\n",
    "    scatter1 = axes[0,0].scatter(metrics_df['total_holding_time'], metrics_df['max_drawdown'], \n",
    "                                alpha=0.6, c=metrics_df['episode_reward'], cmap='RdYlGn')\n",
    "    axes[0,0].set_title('Total Holding Time vs Max Drawdown')\n",
    "    axes[0,0].set_xlabel('Total Holding Time (steps)')\n",
    "    axes[0,0].set_ylabel('Max Drawdown')\n",
    "    plt.colorbar(scatter1, ax=axes[0,0], label='Episode Reward')\n",
    "    \n",
    "    # 2. NVDA holding time vs drawdown\n",
    "    axes[0,1].scatter(metrics_df['nvda_holding_time'], metrics_df['max_drawdown'], \n",
    "                     alpha=0.6, color='green', label='NVDA')\n",
    "    axes[0,1].set_title('NVDA Holding Time vs Max Drawdown')\n",
    "    axes[0,1].set_xlabel('NVDA Holding Time (steps)')\n",
    "    axes[0,1].set_ylabel('Max Drawdown')\n",
    "    \n",
    "    # 3. MSFT holding time vs drawdown\n",
    "    axes[1,0].scatter(metrics_df['msft_holding_time'], metrics_df['max_drawdown'], \n",
    "                     alpha=0.6, color='blue', label='MSFT')\n",
    "    axes[1,0].set_title('MSFT Holding Time vs Max Drawdown')\n",
    "    axes[1,0].set_xlabel('MSFT Holding Time (steps)')\n",
    "    axes[1,0].set_ylabel('Max Drawdown')\n",
    "    \n",
    "    # 4. Holding time distribution by performance quartiles\n",
    "    # Divide episodes into performance quartiles\n",
    "    quartiles = metrics_df['episode_reward'].quantile([0.25, 0.5, 0.75])\n",
    "    \n",
    "    q1_data = metrics_df[metrics_df['episode_reward'] <= quartiles[0.25]]\n",
    "    q2_data = metrics_df[(metrics_df['episode_reward'] > quartiles[0.25]) & \n",
    "                        (metrics_df['episode_reward'] <= quartiles[0.5])]\n",
    "    q3_data = metrics_df[(metrics_df['episode_reward'] > quartiles[0.5]) & \n",
    "                        (metrics_df['episode_reward'] <= quartiles[0.75])]\n",
    "    q4_data = metrics_df[metrics_df['episode_reward'] > quartiles[0.75]]\n",
    "    \n",
    "    axes[1,1].hist([q1_data['total_holding_time'], q2_data['total_holding_time'], \n",
    "                   q3_data['total_holding_time'], q4_data['total_holding_time']], \n",
    "                  bins=15, alpha=0.7, label=['Q1 (worst)', 'Q2', 'Q3', 'Q4 (best)'])\n",
    "    axes[1,1].set_title('Holding Time Distribution by Performance Quartile')\n",
    "    axes[1,1].set_xlabel('Total Holding Time (steps)')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'drawdown_holding_scatter.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n📊 DRAWDOWN vs HOLDING TIME SUMMARY:\")\n",
    "    print(f\"   Average max drawdown: {metrics_df['max_drawdown'].mean():.2f}\")\n",
    "    print(f\"   Average total holding time: {metrics_df['total_holding_time'].mean():.1f} steps\")\n",
    "    print(f\"   Correlation (holding time vs drawdown): {metrics_df['total_holding_time'].corr(metrics_df['max_drawdown']):.3f}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate drawdown vs holding time analysis\n",
    "if phase2_traces:\n",
    "    drawdown_fig = plot_drawdown_holding_scatter(phase2_traces, RESULTS_PATH)\n",
    "    print(\"✅ Drawdown vs holding time scatter saved\")\n",
    "else:\n",
    "    print(\"❌ No action traces available for drawdown analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_distributions(monitor_data, save_path):\n",
    "    \"\"\"\n",
    "    Distribution histograms of ep_len, ep_rew\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Episode Distributions Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combine all monitor data\n",
    "    all_monitor = pd.concat(monitor_data.values(), ignore_index=True)\n",
    "    \n",
    "    # 1. Episode reward distribution\n",
    "    axes[0,0].hist(all_monitor['r'], bins=30, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "    axes[0,0].axvline(all_monitor['r'].mean(), color='red', linestyle='--', \n",
    "                     label=f'Mean: {all_monitor[\"r\"].mean():.3f}')\n",
    "    axes[0,0].axvline(SUCCESS_CRITERIA['ep_rew_mean_min'], color='green', linestyle='--', \n",
    "                     label=f'Target: {SUCCESS_CRITERIA[\"ep_rew_mean_min\"]}')\n",
    "    axes[0,0].set_title('Episode Reward Distribution')\n",
    "    axes[0,0].set_xlabel('Episode Reward')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # 2. Episode length distribution\n",
    "    axes[0,1].hist(all_monitor['l'], bins=30, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "    axes[0,1].axvline(all_monitor['l'].mean(), color='red', linestyle='--', \n",
    "                     label=f'Mean: {all_monitor[\"l\"].mean():.1f}')\n",
    "    axes[0,1].axvline(80, color='orange', linestyle='--', label='Target: 80')\n",
    "    axes[0,1].set_title('Episode Length Distribution')\n",
    "    axes[0,1].set_xlabel('Episode Length (steps)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # 3. Reward vs Length scatter\n",
    "    scatter = axes[0,2].scatter(all_monitor['l'], all_monitor['r'], alpha=0.6)\n",
    "    axes[0,2].set_title('Episode Reward vs Length')\n",
    "    axes[0,2].set_xlabel('Episode Length (steps)')\n",
    "    axes[0,2].set_ylabel('Episode Reward')\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    correlation = all_monitor['l'].corr(all_monitor['r'])\n",
    "    axes[0,2].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                  transform=axes[0,2].transAxes, verticalalignment='top',\n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 4. Seed-wise reward comparison\n",
    "    seed_rewards = []\n",
    "    seed_labels = []\n",
    "    for seed_id, df in monitor_data.items():\n",
    "        seed_rewards.append(df['r'].values)\n",
    "        seed_labels.append(seed_id)\n",
    "    \n",
    "    axes[1,0].boxplot(seed_rewards, labels=seed_labels)\n",
    "    axes[1,0].set_title('Episode Rewards by Seed')\n",
    "    axes[1,0].set_ylabel('Episode Reward')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 5. Seed-wise length comparison\n",
    "    seed_lengths = []\n",
    "    for seed_id, df in monitor_data.items():\n",
    "        seed_lengths.append(df['l'].values)\n",
    "    \n",
    "    axes[1,1].boxplot(seed_lengths, labels=seed_labels)\n",
    "    axes[1,1].set_title('Episode Lengths by Seed')\n",
    "    axes[1,1].set_ylabel('Episode Length (steps)')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 6. Success criteria summary\n",
    "    axes[1,2].axis('off')\n",
    "    \n",
    "    # Calculate success metrics\n",
    "    mean_reward = all_monitor['r'].mean()\n",
    "    mean_length = all_monitor['l'].mean()\n",
    "    reward_success = mean_reward >= SUCCESS_CRITERIA['ep_rew_mean_min']\n",
    "    length_success = mean_length >= 80\n",
    "    \n",
    "    # Calculate Sharpe ratio\n",
    "    sharpe = (all_monitor['r'].mean() / all_monitor['r'].std()) * np.sqrt(252) if all_monitor['r'].std() > 0 else 0\n",
    "    sharpe_success = sharpe >= SUCCESS_CRITERIA['oos_sharpe_min']\n",
    "    \n",
    "    success_text = f\"\"\"\n",
    "PHASE 2 SUCCESS CRITERIA:\n",
    "\n",
    "📊 Episode Reward Mean:\n",
    "   Current: {mean_reward:.3f}\n",
    "   Target:  {SUCCESS_CRITERIA['ep_rew_mean_min']:.3f}\n",
    "   Status:  {'✅ PASS' if reward_success else '❌ FAIL'}\n",
    "\n",
    "📈 Sharpe Ratio:\n",
    "   Current: {sharpe:.3f}\n",
    "   Target:  {SUCCESS_CRITERIA['oos_sharpe_min']:.3f}\n",
    "   Status:  {'✅ PASS' if sharpe_success else '❌ FAIL'}\n",
    "\n",
    "⏱️ Episode Length Mean:\n",
    "   Current: {mean_length:.1f}\n",
    "   Target:  80.0\n",
    "   Status:  {'✅ PASS' if length_success else '❌ FAIL'}\n",
    "\n",
    "🎯 OVERALL STATUS:\n",
    "   {'✅ PHASE 2 SUCCESS' if (reward_success and sharpe_success) else '❌ PHASE 2 NEEDS WORK'}\n",
    "\"\"\"\n",
    "    \n",
    "    axes[1,2].text(0.1, 0.9, success_text, transform=axes[1,2].transAxes, \n",
    "                  verticalalignment='top', fontfamily='monospace', fontsize=10,\n",
    "                  bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'episode_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate episode distributions\n",
    "if monitor_data:\n",
    "    dist_fig = plot_episode_distributions(monitor_data, RESULTS_PATH)\n",
    "    print(\"✅ Episode distributions saved\")\n",
    "else:\n",
    "    print(\"❌ No monitor data available for distribution analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 2 Summary Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phase2_summary_report():\n",
    "    \"\"\"\n",
    "    Generate comprehensive Phase 2 summary report\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Collect all metrics\n",
    "    all_monitor = pd.concat(monitor_data.values(), ignore_index=True)\n",
    "    \n",
    "    mean_reward = all_monitor['r'].mean()\n",
    "    mean_length = all_monitor['l'].mean()\n",
    "    sharpe = (all_monitor['r'].mean() / all_monitor['r'].std()) * np.sqrt(252) if all_monitor['r'].std() > 0 else 0\n",
    "    \n",
    "    # Success criteria evaluation\n",
    "    reward_success = mean_reward >= SUCCESS_CRITERIA['ep_rew_mean_min']\n",
    "    sharpe_success = sharpe >= SUCCESS_CRITERIA['oos_sharpe_min']\n",
    "    overall_success = reward_success and sharpe_success\n",
    "    \n",
    "    # Create summary report\n",
    "    report = {\n",
    "        \"phase\": \"Phase 2: Curriculum Training & Validation\",\n",
    "        \"completion_date\": datetime.now().isoformat(),\n",
    "        \"training_configuration\": {\n",
    "            \"seeds_trained\": len(monitor_data),\n",
    "            \"total_timesteps\": 50000,\n",
    "            \"training_period\": \"2022-01-01 to 2023-12-31\",\n",
    "            \"test_period\": \"2024-01-01 to 2024-12-31\",\n",
    "            \"exit_tax_enabled\": True,\n",
    "            \"governor_enabled\": True\n",
    "        },\n",
    "        \"performance_metrics\": {\n",
    "            \"ep_rew_mean\": float(mean_reward),\n",
    "            \"ep_rew_std\": float(all_monitor['r'].std()),\n",
    "            \"sharpe_ratio\": float(sharpe),\n",
    "            \"ep_len_mean\": float(mean_length),\n",
    "            \"total_episodes\": len(all_monitor)\n",
    "        },\n",
    "        \"success_criteria\": {\n",
    "            \"oos_sharpe_target\": SUCCESS_CRITERIA['oos_sharpe_min'],\n",
    "            \"oos_sharpe_achieved\": float(sharpe),\n",
    "            \"oos_sharpe_success\": sharpe_success,\n",
    "            \"ep_rew_mean_target\": SUCCESS_CRITERIA['ep_rew_mean_min'],\n",
    "            \"ep_rew_mean_achieved\": float(mean_reward),\n",
    "            \"ep_rew_mean_success\": reward_success,\n",
    "            \"overall_success\": overall_success\n",
    "        },\n",
    "        \"top_checkpoints\": checkpoint_rankings.head(10).to_dict('records') if len(checkpoint_rankings) > 0 else [],\n",
    "        \"next_steps\": {\n",
    "            \"proceed_to_phase3\": overall_success,\n",
    "            \"recommended_action\": \"Proceed to Phase 3 Mini-Grid\" if overall_success else \"Investigate reward system tuning\",\n",
    "            \"best_checkpoint\": checkpoint_rankings.iloc[0]['seed_id'] if len(checkpoint_rankings) > 0 else None\n",
    "        },\n",
    "        \"files_generated\": [\n",
    "            \"top10_checkpoints.csv\",\n",
    "            \"reward_components_timeseries.png\",\n",
    "            \"pnl_actions_overlay.png\",\n",
    "            \"drawdown_holding_scatter.png\",\n",
    "            \"episode_distributions.png\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save JSON report\n",
    "    with open(RESULTS_PATH / 'phase2_summary_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    # Generate markdown summary for stakeholders\n",
    "    markdown_summary = f\"\"\"\n",
    "# Phase 2 OOS Training Results - Stairways V3\n",
    "\n",
    "**Completion Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## 🎯 Success Criteria Evaluation\n",
    "\n",
    "| Metric | Target | Achieved | Status |\n",
    "|--------|--------|----------|--------|\n",
    "| OOS Sharpe Ratio | ≥ {SUCCESS_CRITERIA['oos_sharpe_min']} | {sharpe:.3f} | {'✅ PASS' if sharpe_success else '❌ FAIL'} |\n",
    "| Episode Reward Mean | ≥ {SUCCESS_CRITERIA['ep_rew_mean_min']} | {mean_reward:.3f} | {'✅ PASS' if reward_success else '❌ FAIL'} |\n",
    "| **Overall Status** | - | - | **{'✅ SUCCESS' if overall_success else '❌ NEEDS WORK'}** |\n",
    "\n",
    "## 📊 Performance Summary\n",
    "\n",
    "- **Seeds Trained:** {len(monitor_data)}\n",
    "- **Total Episodes:** {len(all_monitor):,}\n",
    "- **Average Episode Length:** {mean_length:.1f} steps\n",
    "- **Episode Reward Std:** {all_monitor['r'].std():.3f}\n",
    "\n",
    "## 🏆 Top 3 Checkpoints\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    if len(checkpoint_rankings) > 0:\n",
    "        for i, (_, row) in enumerate(checkpoint_rankings.head(3).iterrows()):\n",
    "            markdown_summary += f\"\"\"\n",
    "**{i+1}. {row['seed_id']}**\n",
    "- Episode Reward Mean: {row['ep_rew_mean']:.3f}\n",
    "- Sharpe Ratio: {row['sharpe_ratio']:.3f}\n",
    "- Total Episodes: {row['total_episodes']}\n",
    "\"\"\"\n",
    "    \n",
    "    markdown_summary += f\"\"\"\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "**Recommendation:** {report['next_steps']['recommended_action']}\n",
    "\n",
    "{'✅ **PROCEED TO PHASE 3**: Mini-grid hyperparameter optimization' if overall_success else '⚠️ **INVESTIGATE**: Reward system requires tuning before Phase 3'}\n",
    "\n",
    "## 📁 Generated Files\n",
    "\n",
    "- `phase2_summary_report.json` - Complete results data\n",
    "- `top10_checkpoints.csv` - Checkpoint rankings\n",
    "- `reward_components_timeseries.png` - Reward analysis\n",
    "- `pnl_actions_overlay.png` - Trading behavior analysis\n",
    "- `drawdown_holding_scatter.png` - Risk analysis\n",
    "- `episode_distributions.png` - Performance distributions\n",
    "\n",
    "---\n",
    "*Generated by Team B Action-Trace Analysis Template*\n",
    "\"\"\"\n",
    "    \n",
    "    # Save markdown report\n",
    "    with open(RESULTS_PATH / 'phase2_summary_report.md', 'w') as f:\n",
    "        f.write(markdown_summary)\n",
    "    \n",
    "    print(\"\\n📋 PHASE 2 SUMMARY REPORT GENERATED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"📊 Overall Success: {'✅ YES' if overall_success else '❌ NO'}\")\n",
    "    print(f\"📁 Reports saved to: {RESULTS_PATH}\")\n",
    "    print(f\"   - phase2_summary_report.json\")\n",
    "    print(f\"   - phase2_summary_report.md\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate final report\n",
    "final_report = generate_phase2_summary_report()\n",
    "print(\"\\n🎉 Phase 2 Action-Trace Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Team A Customization Notes\n",
    "\n",
    "**🔧 CUSTOMIZATION REQUIRED:**\n",
    "\n",
    "1. **Data Loading Paths**: Update `PHASE2_PATHS` with actual training run directories\n",
    "2. **Action Trace Format**: Modify `load_phase2_action_traces()` based on your actual logging format\n",
    "3. **Reward Components**: Customize `plot_reward_components_timeseries()` for your specific reward system\n",
    "4. **Action Space**: Update action interpretation in `plot_pnl_actions_overlay()` based on your 5-action space\n",
    "5. **Position Tracking**: Verify position change detection logic matches your environment\n",
    "6. **Drawdown Calculation**: Implement your specific drawdown methodology in `plot_drawdown_holding_scatter()`\n",
    "\n",
    "**✅ READY TO USE:**\n",
    "- Checkpoint ranking by ep_rew_mean (primary) and Sharpe (secondary)\n",
    "- Success criteria validation (Sharpe ≥ 0.3, ep_rew_mean ≥ 0.1)\n",
    "- Professional visualization templates\n",
    "- Automated report generation (JSON + Markdown)\n",
    "- Results saved to `../results/phase2/`\n",
    "\n",
    "**🎯 TEAM A TODO:**\n",
    "1. Run Phase 2 OOS training (3 seeds × 50K steps)\n",
    "2. Update paths in Configuration section\n",
    "3. Customize visualization functions for your data structure\n",
    "4. Execute notebook after training completion\n",
    "5. Review generated reports and visualizations\n",
    "6. Share results with stakeholders for Phase 3 approval\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}