{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 Action-Trace Analysis - Stairways V3\n",
    "## OOS Training Results & Top 10 Checkpoint Analysis\n",
    "\n",
    "**Team B Template for Team A Customization**\n",
    "\n",
    "This notebook analyzes Phase 2 OOS training results to:\n",
    "- Rank top 10 checkpoints by ep_rew_mean (secondary: Sharpe ratio)\n",
    "- Generate required visualizations for stakeholder reporting\n",
    "- Validate success criteria: Sharpe ‚â• 0.3, ep_rew_mean ‚â• 0.1\n",
    "\n",
    "**Usage**: Run after Phase 2 OOS training completion (3 seeds √ó 50K steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for professional reports\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"üìä Phase 2 Action-Trace Analysis - Stairways V3\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Team B Template - Ready for Team A Customization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 OOS Training Paths (Team A: Update these paths after training completion)\n",
    "PHASE2_PATHS = [\n",
    "    Path('../train_runs/phase2_oos_seed0'),\n",
    "    Path('../train_runs/phase2_oos_seed1'), \n",
    "    Path('../train_runs/phase2_oos_seed2')\n",
    "]\n",
    "\n",
    "# Results output directory\n",
    "RESULTS_PATH = Path('../results/phase2')\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Success criteria thresholds\n",
    "SUCCESS_CRITERIA = {\n",
    "    'oos_sharpe_min': 0.3,\n",
    "    'ep_rew_mean_min': 0.1,\n",
    "    'top_n_checkpoints': 10\n",
    "}\n",
    "\n",
    "print(f\"üìÅ Configured {len(PHASE2_PATHS)} Phase 2 training paths\")\n",
    "print(f\"üìä Success criteria: Sharpe ‚â• {SUCCESS_CRITERIA['oos_sharpe_min']}, ep_rew_mean ‚â• {SUCCESS_CRITERIA['ep_rew_mean_min']}\")\n",
    "print(f\"üèÜ Will analyze top {SUCCESS_CRITERIA['top_n_checkpoints']} checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phase2_action_traces(seed_paths):\n",
    "    \"\"\"\n",
    "    Load action traces from all Phase 2 OOS runs\n",
    "    \n",
    "    Args:\n",
    "        seed_paths: List of Path objects to seed run directories\n",
    "        \n",
    "    Returns:\n",
    "        dict: {seed_id: action_trace_dataframe}\n",
    "    \"\"\"\n",
    "    action_traces = {}\n",
    "    \n",
    "    for i, seed_path in enumerate(seed_paths):\n",
    "        seed_id = f\"seed_{i}\"\n",
    "        \n",
    "        # Try multiple possible action trace file formats\n",
    "        possible_files = [\n",
    "            seed_path / 'action_traces.csv',\n",
    "            seed_path / 'action_traces.parquet',\n",
    "            seed_path / 'detailed_logs.csv'\n",
    "        ]\n",
    "        \n",
    "        loaded = False\n",
    "        for trace_file in possible_files:\n",
    "            if trace_file.exists():\n",
    "                try:\n",
    "                    if trace_file.suffix == '.parquet':\n",
    "                        df = pd.read_parquet(trace_file)\n",
    "                    else:\n",
    "                        df = pd.read_csv(trace_file)\n",
    "                    \n",
    "                    df['seed_id'] = seed_id\n",
    "                    action_traces[seed_id] = df\n",
    "                    print(f\"‚úÖ Loaded {len(df)} action records from {seed_id}\")\n",
    "                    loaded = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to load {trace_file}: {e}\")\n",
    "        \n",
    "        if not loaded:\n",
    "            print(f\"‚ùå No action traces found for {seed_id}\")\n",
    "            # Create sample data for template demonstration\n",
    "            print(f\"üìù Creating sample data for {seed_id}\")\n",
    "            np.random.seed(42 + i)\n",
    "            n_episodes = 50\n",
    "            n_steps_per_ep = 100\n",
    "            n_samples = n_episodes * n_steps_per_ep\n",
    "            \n",
    "            sample_df = pd.DataFrame({\n",
    "                'episode_id': np.repeat(range(n_episodes), n_steps_per_ep),\n",
    "                'step': np.tile(range(n_steps_per_ep), n_episodes),\n",
    "                'episode_reward': np.repeat(np.random.normal(0.15, 0.8, n_episodes), n_steps_per_ep),\n",
    "                'step_reward': np.random.normal(0.001, 0.05, n_samples),\n",
    "                'nvda_position': np.random.choice([-1, 0, 1], n_samples, p=[0.25, 0.5, 0.25]),\n",
    "                'msft_position': np.random.choice([-1, 0, 1], n_samples, p=[0.25, 0.5, 0.25]),\n",
    "                'step_pnl': np.random.normal(0, 25, n_samples),\n",
    "                'nvda_price': 485 + np.cumsum(np.random.normal(0, 2, n_samples)),\n",
    "                'msft_price': 412 + np.cumsum(np.random.normal(0, 1.5, n_samples)),\n",
    "                'action': np.random.randint(0, 5, n_samples),\n",
    "                'timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='1min'),\n",
    "                'seed_id': seed_id\n",
    "            })\n",
    "            action_traces[seed_id] = sample_df\n",
    "    \n",
    "    return action_traces\n",
    "\n",
    "# Load all Phase 2 action traces\n",
    "phase2_traces = load_phase2_action_traces(PHASE2_PATHS)\n",
    "print(f\"\\nüìà Total seeds loaded: {len(phase2_traces)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Monitor.csv Analysis & Checkpoint Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_monitor_data(seed_paths):\n",
    "    \"\"\"\n",
    "    Load monitor.csv files from all Phase 2 runs for checkpoint ranking\n",
    "    \n",
    "    Returns:\n",
    "        dict: {seed_id: monitor_dataframe}\n",
    "    \"\"\"\n",
    "    monitor_data = {}\n",
    "    \n",
    "    for i, seed_path in enumerate(seed_paths):\n",
    "        seed_id = f\"seed_{i}\"\n",
    "        monitor_file = seed_path / 'monitor.csv'\n",
    "        \n",
    "        if monitor_file.exists():\n",
    "            try:\n",
    "                # Load monitor.csv (skip comment lines starting with #)\n",
    "                df = pd.read_csv(monitor_file, comment='#')\n",
    "                df['seed_id'] = seed_id\n",
    "                monitor_data[seed_id] = df\n",
    "                print(f\"‚úÖ Loaded {len(df)} episodes from {seed_id} monitor.csv\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to load monitor.csv for {seed_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No monitor.csv found for {seed_id}, creating sample data\")\n",
    "            # Create sample monitor data\n",
    "            np.random.seed(42 + i)\n",
    "            n_episodes = 50\n",
    "            sample_monitor = pd.DataFrame({\n",
    "                'r': np.random.normal(0.15, 0.8, n_episodes),  # episode rewards\n",
    "                'l': np.random.randint(60, 120, n_episodes),    # episode lengths\n",
    "                't': np.cumsum(np.random.randint(60, 120, n_episodes)),  # timestamps\n",
    "                'seed_id': seed_id\n",
    "            })\n",
    "            monitor_data[seed_id] = sample_monitor\n",
    "    \n",
    "    return monitor_data\n",
    "\n",
    "# Load monitor data\n",
    "monitor_data = load_monitor_data(PHASE2_PATHS)\n",
    "print(f\"\\nüìä Monitor data loaded for {len(monitor_data)} seeds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_top10_checkpoints(monitor_data, success_criteria):\n",
    "    \"\"\"\n",
    "    Rank checkpoints by ep_rew_mean, secondary by Sharpe ratio\n",
    "    \n",
    "    Args:\n",
    "        monitor_data: Dict of monitor dataframes by seed\n",
    "        success_criteria: Dict with ranking criteria\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Ranked checkpoint results\n",
    "    \"\"\"\n",
    "    checkpoint_results = []\n",
    "    \n",
    "    for seed_id, df in monitor_data.items():\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate key metrics\n",
    "        ep_rew_mean = df['r'].mean()\n",
    "        ep_rew_std = df['r'].std()\n",
    "        ep_len_mean = df['l'].mean()\n",
    "        \n",
    "        # Calculate Sharpe ratio (episode-level returns, annualized)\n",
    "        if ep_rew_std > 0:\n",
    "            sharpe = (ep_rew_mean / ep_rew_std) * np.sqrt(252)  # Assuming daily episodes\n",
    "        else:\n",
    "            sharpe = 0\n",
    "        \n",
    "        # Success criteria checks\n",
    "        meets_sharpe = sharpe >= success_criteria['oos_sharpe_min']\n",
    "        meets_reward = ep_rew_mean >= success_criteria['ep_rew_mean_min']\n",
    "        \n",
    "        checkpoint_results.append({\n",
    "            'seed_id': seed_id,\n",
    "            'ep_rew_mean': ep_rew_mean,\n",
    "            'ep_rew_std': ep_rew_std,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'ep_len_mean': ep_len_mean,\n",
    "            'total_episodes': len(df),\n",
    "            'meets_sharpe_criteria': meets_sharpe,\n",
    "            'meets_reward_criteria': meets_reward,\n",
    "            'overall_success': meets_sharpe and meets_reward\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and rank\n",
    "    results_df = pd.DataFrame(checkpoint_results)\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        # Primary ranking: ep_rew_mean (descending)\n",
    "        # Secondary ranking: sharpe_ratio (descending)\n",
    "        results_df = results_df.sort_values(\n",
    "            ['ep_rew_mean', 'sharpe_ratio'], \n",
    "            ascending=[False, False]\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        # Add ranking\n",
    "        results_df['rank'] = range(1, len(results_df) + 1)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Rank checkpoints\n",
    "checkpoint_rankings = rank_top10_checkpoints(monitor_data, SUCCESS_CRITERIA)\n",
    "\n",
    "print(\"\\nüèÜ TOP 10 CHECKPOINT RANKINGS\")\n",
    "print(\"=\" * 80)\n",
    "if len(checkpoint_rankings) > 0:\n",
    "    top_10 = checkpoint_rankings.head(SUCCESS_CRITERIA['top_n_checkpoints'])\n",
    "    \n",
    "    for _, row in top_10.iterrows():\n",
    "        success_icon = \"‚úÖ\" if row['overall_success'] else \"‚ùå\"\n",
    "        print(f\"{success_icon} Rank {row['rank']:2d}: {row['seed_id']} | \"\n",
    "              f\"Reward: {row['ep_rew_mean']:6.3f} | \"\n",
    "              f\"Sharpe: {row['sharpe_ratio']:6.3f} | \"\n",
    "              f\"Episodes: {row['total_episodes']:3d}\")\n",
    "    \n",
    "    # Success summary\n",
    "    successful_checkpoints = checkpoint_rankings[checkpoint_rankings['overall_success']]\n",
    "    print(f\"\\nüìä SUCCESS SUMMARY:\")\n",
    "    print(f\"   Checkpoints meeting both criteria: {len(successful_checkpoints)}/{len(checkpoint_rankings)}\")\n",
    "    print(f\"   Best ep_rew_mean: {checkpoint_rankings['ep_rew_mean'].max():.3f}\")\n",
    "    print(f\"   Best Sharpe ratio: {checkpoint_rankings['sharpe_ratio'].max():.3f}\")\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint data available for ranking\")\n",
    "\n",
    "# Save rankings to file\n",
    "checkpoint_rankings.to_csv(RESULTS_PATH / 'top10_checkpoints.csv', index=False)\n",
    "print(f\"\\nüíæ Rankings saved to: {RESULTS_PATH / 'top10_checkpoints.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Required Visualizations\n",
    "### Team A: Customize these visualization functions based on your specific data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_components_timeseries(action_traces, save_path):\n",
    "    \"\"\"\n",
    "    Time-series of reward components per episode\n",
    "    \n",
    "    Team A: Customize this function based on your reward system components\n",
    "    Expected components: pnl_reward, holding_bonus, exit_tax, smoothed_penalty\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Reward Components Time Series Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combine all seeds for analysis\n",
    "    all_traces = pd.concat(action_traces.values(), ignore_index=True)\n",
    "    \n",
    "    # Episode-level aggregation\n",
    "    episode_rewards = all_traces.groupby(['seed_id', 'episode_id']).agg({\n",
    "        'episode_reward': 'first',\n",
    "        'step_reward': 'sum',\n",
    "        'step_pnl': 'sum',\n",
    "        'step': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # 1. Episode rewards over time\n",
    "    for seed_id in episode_rewards['seed_id'].unique():\n",
    "        seed_data = episode_rewards[episode_rewards['seed_id'] == seed_id]\n",
    "        axes[0,0].plot(seed_data['episode_id'], seed_data['episode_reward'], \n",
    "                      alpha=0.7, label=seed_id, linewidth=1)\n",
    "    \n",
    "    axes[0,0].set_title('Episode Rewards Over Time')\n",
    "    axes[0,0].set_xlabel('Episode ID')\n",
    "    axes[0,0].set_ylabel('Episode Reward')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cumulative P&L\n",
    "    for seed_id in episode_rewards['seed_id'].unique():\n",
    "        seed_data = episode_rewards[episode_rewards['seed_id'] == seed_id]\n",
    "        cumulative_pnl = seed_data['step_pnl'].cumsum()\n",
    "        axes[0,1].plot(seed_data['episode_id'], cumulative_pnl, \n",
    "                      alpha=0.7, label=seed_id, linewidth=2)\n",
    "    \n",
    "    axes[0,1].set_title('Cumulative P&L Over Episodes')\n",
    "    axes[0,1].set_xlabel('Episode ID')\n",
    "    axes[0,1].set_ylabel('Cumulative P&L')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Episode length distribution\n",
    "    axes[1,0].hist(episode_rewards['step'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].axvline(episode_rewards['step'].mean(), color='red', linestyle='--', \n",
    "                     label=f'Mean: {episode_rewards[\"step\"].mean():.1f}')\n",
    "    axes[1,0].set_title('Episode Length Distribution')\n",
    "    axes[1,0].set_xlabel('Episode Length (steps)')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # 4. Reward vs Episode Length scatter\n",
    "    scatter = axes[1,1].scatter(episode_rewards['step'], episode_rewards['episode_reward'], \n",
    "                               alpha=0.6, c=episode_rewards['step_pnl'], cmap='RdYlGn')\n",
    "    axes[1,1].set_title('Episode Reward vs Length (colored by P&L)')\n",
    "    axes[1,1].set_xlabel('Episode Length (steps)')\n",
    "    axes[1,1].set_ylabel('Episode Reward')\n",
    "    plt.colorbar(scatter, ax=axes[1,1], label='Total P&L')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'reward_components_timeseries.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate reward components visualization\n",
    "if phase2_traces:\n",
    "    reward_fig = plot_reward_components_timeseries(phase2_traces, RESULTS_PATH)\n",
    "    print(\"‚úÖ Reward components time series saved\")\n",
    "else:\n",
    "    print(\"‚ùå No action traces available for reward analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pnl_actions_overlay(action_traces, save_path):\n",
    "    \"\"\"\n",
    "    P&L vs action overlay with trade markers on price chart\n",
    "    \n",
    "    Team A: Customize based on your action space and position tracking\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "    fig.suptitle('P&L vs Actions Overlay Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Use best performing seed for detailed analysis\n",
    "    if len(checkpoint_rankings) > 0:\n",
    "        best_seed = checkpoint_rankings.iloc[0]['seed_id']\n",
    "        trace_data = phase2_traces[best_seed]\n",
    "        print(f\"üìä Analyzing best performing seed: {best_seed}\")\n",
    "    else:\n",
    "        # Use first available seed\n",
    "        best_seed = list(phase2_traces.keys())[0]\n",
    "        trace_data = phase2_traces[best_seed]\n",
    "        print(f\"üìä Analyzing seed: {best_seed}\")\n",
    "    \n",
    "    # Select a representative episode for detailed view\n",
    "    episode_rewards = trace_data.groupby('episode_id')['episode_reward'].first()\n",
    "    best_episode_id = episode_rewards.idxmax()\n",
    "    episode_data = trace_data[trace_data['episode_id'] == best_episode_id].copy()\n",
    "    episode_data = episode_data.sort_values('step')\n",
    "    \n",
    "    print(f\"üìà Analyzing best episode: {best_episode_id} (reward: {episode_rewards[best_episode_id]:.3f})\")\n",
    "    \n",
    "    # 1. NVDA Price with position markers\n",
    "    axes[0].plot(episode_data['step'], episode_data['nvda_price'], 'b-', linewidth=2, label='NVDA Price')\n",
    "    \n",
    "    # Mark position changes\n",
    "    position_changes = episode_data[episode_data['nvda_position'].diff() != 0]\n",
    "    for _, row in position_changes.iterrows():\n",
    "        color = 'green' if row['nvda_position'] > 0 else 'red' if row['nvda_position'] < 0 else 'gray'\n",
    "        marker = '^' if row['nvda_position'] > 0 else 'v' if row['nvda_position'] < 0 else 'o'\n",
    "        axes[0].scatter(row['step'], row['nvda_price'], color=color, marker=marker, s=100, alpha=0.8)\n",
    "    \n",
    "    axes[0].set_title(f'NVDA Price with Position Changes (Episode {best_episode_id})')\n",
    "    axes[0].set_ylabel('NVDA Price')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. MSFT Price with position markers\n",
    "    axes[1].plot(episode_data['step'], episode_data['msft_price'], 'r-', linewidth=2, label='MSFT Price')\n",
    "    \n",
    "    position_changes = episode_data[episode_data['msft_position'].diff() != 0]\n",
    "    for _, row in position_changes.iterrows():\n",
    "        color = 'green' if row['msft_position'] > 0 else 'red' if row['msft_position'] < 0 else 'gray'\n",
    "        marker = '^' if row['msft_position'] > 0 else 'v' if row['msft_position'] < 0 else 'o'\n",
    "        axes[1].scatter(row['step'], row['msft_price'], color=color, marker=marker, s=100, alpha=0.8)\n",
    "    \n",
    "    axes[1].set_title(f'MSFT Price with Position Changes (Episode {best_episode_id})')\n",
    "    axes[1].set_ylabel('MSFT Price')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Cumulative P&L with action markers\n",
    "    episode_data['cumulative_pnl'] = episode_data['step_pnl'].cumsum()\n",
    "    axes[2].plot(episode_data['step'], episode_data['cumulative_pnl'], 'g-', linewidth=2, label='Cumulative P&L')\n",
    "    \n",
    "    # Mark significant actions\n",
    "    action_changes = episode_data[episode_data['action'].diff() != 0]\n",
    "    for _, row in action_changes.iterrows():\n",
    "        axes[2].scatter(row['step'], row['cumulative_pnl'], color='orange', marker='D', s=60, alpha=0.7)\n",
    "    \n",
    "    axes[2].set_title(f'Cumulative P&L with Action Changes (Episode {best_episode_id})')\n",
    "    axes[2].set_xlabel('Time Step')\n",
    "    axes[2].set_ylabel('Cumulative P&L')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'pnl_actions_overlay.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate P&L vs actions overlay\n",
    "if phase2_traces:\n",
    "    pnl_fig = plot_pnl_actions_overlay(phase2_traces, RESULTS_PATH)\n",
    "    print(\"‚úÖ P&L vs actions overlay saved\")\n",
    "else:\n",
    "    print(\"‚ùå No action traces available for P&L analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_drawdown_holding_scatter(action_traces, save_path):\n",
    "    \"\"\"\n",
    "    Drawdown vs holding time scatter plot\n",
    "    \n",
    "    Team A: Customize based on your drawdown calculation method\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Drawdown vs Holding Time Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combine all traces for comprehensive analysis\n",
    "    all_traces = pd.concat(phase2_traces.values(), ignore_index=True)\n",
    "    \n",
    "    # Calculate episode-level metrics\n",
    "    episode_metrics = []\n",
    "    \n",
    "    for (seed_id, episode_id), episode_data in all_traces.groupby(['seed_id', 'episode_id']):\n",
    "        episode_data = episode_data.sort_values('step')\n",
    "        \n",
    "        # Calculate cumulative P&L and drawdown\n",
    "        cumulative_pnl = episode_data['step_pnl'].cumsum()\n",
    "        running_max = cumulative_pnl.expanding().max()\n",
    "        drawdown = cumulative_pnl - running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Calculate holding times for each position\n",
    "        nvda_holding_time = 0\n",
    "        msft_holding_time = 0\n",
    "        \n",
    "        # Simple holding time calculation (consecutive non-zero positions)\n",
    "        nvda_positions = episode_data['nvda_position'].values\n",
    "        msft_positions = episode_data['msft_position'].values\n",
    "        \n",
    "        # Count consecutive holding periods\n",
    "        nvda_holding_time = np.sum(nvda_positions != 0)\n",
    "        msft_holding_time = np.sum(msft_positions != 0)\n",
    "        total_holding_time = nvda_holding_time + msft_holding_time\n",
    "        \n",
    "        episode_metrics.append({\n",
    "            'seed_id': seed_id,\n",
    "            'episode_id': episode_id,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'nvda_holding_time': nvda_holding_time,\n",
    "            'msft_holding_time': msft_holding_time,\n",
    "            'total_holding_time': total_holding_time,\n",
    "            'episode_reward': episode_data['episode_reward'].iloc[0],\n",
    "            'episode_length': len(episode_data)\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(episode_metrics)\n",
    "    \n",
    "    # 1. Total holding time vs max drawdown\n",
    "    scatter1 = axes[0,0].scatter(metrics_df['total_holding_time'], metrics_df['max_drawdown'], \n",
    "                                alpha=0.6, c=metrics_df['episode_reward'], cmap='RdYlGn')\n",
    "    axes[0,0].set_title('Total Holding Time vs Max Drawdown')\n",
    "    axes[0,0].set_xlabel('Total Holding Time (steps)')\n",
    "    axes[0,0].set_ylabel('Max Drawdown')\n",
    "    plt.colorbar(scatter1, ax=axes[0,0], label='Episode Reward')\n",
    "    \n",
    "    # 2. NVDA holding time vs drawdown\n",
    "    axes[0,1].scatter(metrics_df['nvda_holding_time'], metrics_df['max_drawdown'], \n",
    "                     alpha=0.6, color='green', label='NVDA')\n",
    "    axes[0,1].set_title('NVDA Holding Time vs Max Drawdown')\n",
    "    axes[0,1].set_xlabel('NVDA Holding Time (steps)')\n",
    "    axes[0,1].set_ylabel('Max Drawdown')\n",
    "    \n",
    "    # 3. MSFT holding time vs drawdown\n",
    "    axes[1,0].scatter(metrics_df['msft_holding_time'], metrics_df['max_drawdown'], \n",
    "                     alpha=0.6, color='blue', label='MSFT')\n",
    "    axes[1,0].set_title('MSFT Holding Time vs Max Drawdown')\n",
    "    axes[1,0].set_xlabel('MSFT Holding Time (steps)')\n",
    "    axes[1,0].set_ylabel('Max Drawdown')\n",
    "    \n",
    "    # 4. Holding time distribution by performance quartiles\n",
    "    # Divide episodes into performance quartiles\n",
    "    quartiles = metrics_df['episode_reward'].quantile([0.25, 0.5, 0.75])\n",
    "    \n",
    "    q1_data = metrics_df[metrics_df['episode_reward'] <= quartiles[0.25]]\n",
    "    q2_data = metrics_df[(metrics_df['episode_reward'] > quartiles[0.25]) & \n",
    "                        (metrics_df['episode_reward'] <= quartiles[0.5])]\n",
    "    q3_data = metrics_df[(metrics_df['episode_reward'] > quartiles[0.5]) & \n",
    "                        (metrics_df['episode_reward'] <= quartiles[0.75])]\n",
    "    q4_data = metrics_df[metrics_df['episode_reward'] > quartiles[0.75]]\n",
    "    \n",
    "    axes[1,1].hist([q1_data['total_holding_time'], q2_data['total_holding_time'], \n",
    "                   q3_data['total_holding_time'], q4_data['total_holding_time']], \n",
    "                  bins=15, alpha=0.7, label=['Q1 (worst)', 'Q2', 'Q3', 'Q4 (best)'])\n",
    "    axes[1,1].set_title('Holding Time Distribution by Performance Quartile')\n",
    "    axes[1,1].set_xlabel('Total Holding Time (steps)')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'drawdown_holding_scatter.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nüìä DRAWDOWN vs HOLDING TIME SUMMARY:\")\n",
    "    print(f\"   Average max drawdown: {metrics_df['max_drawdown'].mean():.2f}\")\n",
    "    print(f\"   Average total holding time: {metrics_df['total_holding_time'].mean():.1f} steps\")\n",
    "    print(f\"   Correlation (holding time vs drawdown): {metrics_df['total_holding_time'].corr(metrics_df['max_drawdown']):.3f}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate drawdown vs holding time analysis\n",
    "if phase2_traces:\n",
    "    drawdown_fig = plot_drawdown_holding_scatter(phase2_traces, RESULTS_PATH)\n",
    "    print(\"‚úÖ Drawdown vs holding time scatter saved\")\n",
    "else:\n",
    "    print(\"‚ùå No action traces available for drawdown analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_distributions(monitor_data, save_path):\n",
    "    \"\"\"\n",
    "    Distribution histograms of ep_len, ep_rew\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Episode Distributions Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Combine all monitor data\n",
    "    all_monitor = pd.concat(monitor_data.values(), ignore_index=True)\n",
    "    \n",
    "    # 1. Episode reward distribution\n",
    "    axes[0,0].hist(all_monitor['r'], bins=30, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "    axes[0,0].axvline(all_monitor['r'].mean(), color='red', linestyle='--', \n",
    "                     label=f'Mean: {all_monitor[\"r\"].mean():.3f}')\n",
    "    axes[0,0].axvline(SUCCESS_CRITERIA['ep_rew_mean_min'], color='green', linestyle='--', \n",
    "                     label=f'Target: {SUCCESS_CRITERIA[\"ep_rew_mean_min\"]}')\n",
    "    axes[0,0].set_title('Episode Reward Distribution')\n",
    "    axes[0,0].set_xlabel('Episode Reward')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # 2. Episode length distribution\n",
    "    axes[0,1].hist(all_monitor['l'], bins=30, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "    axes[0,1].axvline(all_monitor['l'].mean(), color='red', linestyle='--', \n",
    "                     label=f'Mean: {all_monitor[\"l\"].mean():.1f}')\n",
    "    axes[0,1].axvline(80, color='orange', linestyle='--', label='Target: 80')\n",
    "    axes[0,1].set_title('Episode Length Distribution')\n",
    "    axes[0,1].set_xlabel('Episode Length (steps)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # 3. Reward vs Length scatter\n",
    "    scatter = axes[0,2].scatter(all_monitor['l'], all_monitor['r'], alpha=0.6)\n",
    "    axes[0,2].set_title('Episode Reward vs Length')\n",
    "    axes[0,2].set_xlabel('Episode Length (steps)')\n",
    "    axes[0,2].set_ylabel('Episode Reward')\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    correlation = all_monitor['l'].corr(all_monitor['r'])\n",
    "    axes[0,2].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                  transform=axes[0,2].transAxes, verticalalignment='top',\n",
    "                  bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # 4. Seed-wise reward comparison\n",
    "    seed_rewards = []\n",
    "    seed_labels = []\n",
    "    for seed_id, df in monitor_data.items():\n",
    "        seed_rewards.append(df['r'].values)\n",
    "        seed_labels.append(seed_id)\n",
    "    \n",
    "    axes[1,0].boxplot(seed_rewards, labels=seed_labels)\n",
    "    axes[1,0].set_title('Episode Rewards by Seed')\n",
    "    axes[1,0].set_ylabel('Episode Reward')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 5. Seed-wise length comparison\n",
    "    seed_lengths = []\n",
    "    for seed_id, df in monitor_data.items():\n",
    "        seed_lengths.append(df['l'].values)\n",
    "    \n",
    "    axes[1,1].boxplot(seed_lengths, labels=seed_labels)\n",
    "    axes[1,1].set_title('Episode Lengths by Seed')\n",
    "    axes[1,1].set_ylabel('Episode Length (steps)')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 6. Success criteria summary\n",
    "    axes[1,2].axis('off')\n",
    "    \n",
    "    # Calculate success metrics\n",
    "    mean_reward = all_monitor['r'].mean()\n",
    "    mean_length = all_monitor['l'].mean()\n",
    "    reward_success = mean_reward >= SUCCESS_CRITERIA['ep_rew_mean_min']\n",
    "    length_success = mean_length >= 80\n",
    "    \n",
    "    # Calculate Sharpe ratio\n",
    "    sharpe = (all_monitor['r'].mean() / all_monitor['r'].std()) * np.sqrt(252) if all_monitor['r'].std() > 0 else 0\n",
    "    sharpe_success = sharpe >= SUCCESS_CRITERIA['oos_sharpe_min']\n",
    "    \n",
    "    success_text = f\"\"\"\n",
    "PHASE 2 SUCCESS CRITERIA:\n",
    "\n",
    "üìä Episode Reward Mean:\n",
    "   Current: {mean_reward:.3f}\n",
    "   Target:  {SUCCESS_CRITERIA['ep_rew_mean_min']:.3f}\n",
    "   Status:  {'‚úÖ PASS' if reward_success else '‚ùå FAIL'}\n",
    "\n",
    "üìà Sharpe Ratio:\n",
    "   Current: {sharpe:.3f}\n",
    "   Target:  {SUCCESS_CRITERIA['oos_sharpe_min']:.3f}\n",
    "   Status:  {'‚úÖ PASS' if sharpe_success else '‚ùå FAIL'}\n",
    "\n",
    "‚è±Ô∏è Episode Length Mean:\n",
    "   Current: {mean_length:.1f}\n",
    "   Target:  80.0\n",
    "   Status:  {'‚úÖ PASS' if length_success else '‚ùå FAIL'}\n",
    "\n",
    "üéØ OVERALL STATUS:\n",
    "   {'‚úÖ PHASE 2 SUCCESS' if (reward_success and sharpe_success) else '‚ùå PHASE 2 NEEDS WORK'}\n",
    "\"\"\"\n",
    "    \n",
    "    axes[1,2].text(0.1, 0.9, success_text, transform=axes[1,2].transAxes, \n",
    "                  verticalalignment='top', fontfamily='monospace', fontsize=10,\n",
    "                  bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path / 'episode_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate episode distributions\n",
    "if monitor_data:\n",
    "    dist_fig = plot_episode_distributions(monitor_data, RESULTS_PATH)\n",
    "    print(\"‚úÖ Episode distributions saved\")\n",
    "else:\n",
    "    print(\"‚ùå No monitor data available for distribution analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 2 Summary Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phase2_summary_report():\n",
    "    \"\"\"\n",
    "    Generate comprehensive Phase 2 summary report\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Collect all metrics\n",
    "    all_monitor = pd.concat(monitor_data.values(), ignore_index=True)\n",
    "    \n",
    "    mean_reward = all_monitor['r'].mean()\n",
    "    mean_length = all_monitor['l'].mean()\n",
    "    sharpe = (all_monitor['r'].mean() / all_monitor['r'].std()) * np.sqrt(252) if all_monitor['r'].std() > 0 else 0\n",
    "    \n",
    "    # Success criteria evaluation\n",
    "    reward_success = mean_reward >= SUCCESS_CRITERIA['ep_rew_mean_min']\n",
    "    sharpe_success = sharpe >= SUCCESS_CRITERIA['oos_sharpe_min']\n",
    "    overall_success = reward_success and sharpe_success\n",
    "    \n",
    "    # Create summary report\n",
    "    report = {\n",
    "        \"phase\": \"Phase 2: Curriculum Training & Validation\",\n",
    "        \"completion_date\": datetime.now().isoformat(),\n",
    "        \"training_configuration\": {\n",
    "            \"seeds_trained\": len(monitor_data),\n",
    "            \"total_timesteps\": 50000,\n",
    "            \"training_period\": \"2022-01-01 to 2023-12-31\",\n",
    "            \"test_period\": \"2024-01-01 to 2024-12-31\",\n",
    "            \"exit_tax_enabled\": True,\n",
    "            \"governor_enabled\": True\n",
    "        },\n",
    "        \"performance_metrics\": {\n",
    "            \"ep_rew_mean\": float(mean_reward),\n",
    "            \"ep_rew_std\": float(all_monitor['r'].std()),\n",
    "            \"sharpe_ratio\": float(sharpe),\n",
    "            \"ep_len_mean\": float(mean_length),\n",
    "            \"total_episodes\": len(all_monitor)\n",
    "        },\n",
    "        \"success_criteria\": {\n",
    "            \"oos_sharpe_target\": SUCCESS_CRITERIA['oos_sharpe_min'],\n",
    "            \"oos_sharpe_achieved\": float(sharpe),\n",
    "            \"oos_sharpe_success\": sharpe_success,\n",
    "            \"ep_rew_mean_target\": SUCCESS_CRITERIA['ep_rew_mean_min'],\n",
    "            \"ep_rew_mean_achieved\": float(mean_reward),\n",
    "            \"ep_rew_mean_success\": reward_success,\n",
    "            \"overall_success\": overall_success\n",
    "        },\n",
    "        \"top_checkpoints\": checkpoint_rankings.head(10).to_dict('records') if len(checkpoint_rankings) > 0 else [],\n",
    "        \"next_steps\": {\n",
    "            \"proceed_to_phase3\": overall_success,\n",
    "            \"recommended_action\": \"Proceed to Phase 3 Mini-Grid\" if overall_success else \"Investigate reward system tuning\",\n",
    "            \"best_checkpoint\": checkpoint_rankings.iloc[0]['seed_id'] if len(checkpoint_rankings) > 0 else None\n",
    "        },\n",
    "        \"files_generated\": [\n",
    "            \"top10_checkpoints.csv\",\n",
    "            \"reward_components_timeseries.png\",\n",
    "            \"pnl_actions_overlay.png\",\n",
    "            \"drawdown_holding_scatter.png\",\n",
    "            \"episode_distributions.png\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save JSON report\n",
    "    with open(RESULTS_PATH / 'phase2_summary_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    # Generate markdown summary for stakeholders\n",
    "    markdown_summary = f\"\"\"\n",
    "# Phase 2 OOS Training Results - Stairways V3\n",
    "\n",
    "**Completion Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## üéØ Success Criteria Evaluation\n",
    "\n",
    "| Metric | Target | Achieved | Status |\n",
    "|--------|--------|----------|--------|\n",
    "| OOS Sharpe Ratio | ‚â• {SUCCESS_CRITERIA['oos_sharpe_min']} | {sharpe:.3f} | {'‚úÖ PASS' if sharpe_success else '‚ùå FAIL'} |\n",
    "| Episode Reward Mean | ‚â• {SUCCESS_CRITERIA['ep_rew_mean_min']} | {mean_reward:.3f} | {'‚úÖ PASS' if reward_success else '‚ùå FAIL'} |\n",
    "| **Overall Status** | - | - | **{'‚úÖ SUCCESS' if overall_success else '‚ùå NEEDS WORK'}** |\n",
    "\n",
    "## üìä Performance Summary\n",
    "\n",
    "- **Seeds Trained:** {len(monitor_data)}\n",
    "- **Total Episodes:** {len(all_monitor):,}\n",
    "- **Average Episode Length:** {mean_length:.1f} steps\n",
    "- **Episode Reward Std:** {all_monitor['r'].std():.3f}\n",
    "\n",
    "## üèÜ Top 3 Checkpoints\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    if len(checkpoint_rankings) > 0:\n",
    "        for i, (_, row) in enumerate(checkpoint_rankings.head(3).iterrows()):\n",
    "            markdown_summary += f\"\"\"\n",
    "**{i+1}. {row['seed_id']}**\n",
    "- Episode Reward Mean: {row['ep_rew_mean']:.3f}\n",
    "- Sharpe Ratio: {row['sharpe_ratio']:.3f}\n",
    "- Total Episodes: {row['total_episodes']}\n",
    "\"\"\"\n",
    "    \n",
    "    markdown_summary += f\"\"\"\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Recommendation:** {report['next_steps']['recommended_action']}\n",
    "\n",
    "{'‚úÖ **PROCEED TO PHASE 3**: Mini-grid hyperparameter optimization' if overall_success else '‚ö†Ô∏è **INVESTIGATE**: Reward system requires tuning before Phase 3'}\n",
    "\n",
    "## üìÅ Generated Files\n",
    "\n",
    "- `phase2_summary_report.json` - Complete results data\n",
    "- `top10_checkpoints.csv` - Checkpoint rankings\n",
    "- `reward_components_timeseries.png` - Reward analysis\n",
    "- `pnl_actions_overlay.png` - Trading behavior analysis\n",
    "- `drawdown_holding_scatter.png` - Risk analysis\n",
    "- `episode_distributions.png` - Performance distributions\n",
    "\n",
    "---\n",
    "*Generated by Team B Action-Trace Analysis Template*\n",
    "\"\"\"\n",
    "    \n",
    "    # Save markdown report\n",
    "    with open(RESULTS_PATH / 'phase2_summary_report.md', 'w') as f:\n",
    "        f.write(markdown_summary)\n",
    "    \n",
    "    print(\"\\nüìã PHASE 2 SUMMARY REPORT GENERATED\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìä Overall Success: {'‚úÖ YES' if overall_success else '‚ùå NO'}\")\n",
    "    print(f\"üìÅ Reports saved to: {RESULTS_PATH}\")\n",
    "    print(f\"   - phase2_summary_report.json\")\n",
    "    print(f\"   - phase2_summary_report.md\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate final report\n",
    "final_report = generate_phase2_summary_report()\n",
    "print(\"\\nüéâ Phase 2 Action-Trace Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Team A Customization Notes\n",
    "\n",
    "**üîß CUSTOMIZATION REQUIRED:**\n",
    "\n",
    "1. **Data Loading Paths**: Update `PHASE2_PATHS` with actual training run directories\n",
    "2. **Action Trace Format**: Modify `load_phase2_action_traces()` based on your actual logging format\n",
    "3. **Reward Components**: Customize `plot_reward_components_timeseries()` for your specific reward system\n",
    "4. **Action Space**: Update action interpretation in `plot_pnl_actions_overlay()` based on your 5-action space\n",
    "5. **Position Tracking**: Verify position change detection logic matches your environment\n",
    "6. **Drawdown Calculation**: Implement your specific drawdown methodology in `plot_drawdown_holding_scatter()`\n",
    "\n",
    "**‚úÖ READY TO USE:**\n",
    "- Checkpoint ranking by ep_rew_mean (primary) and Sharpe (secondary)\n",
    "- Success criteria validation (Sharpe ‚â• 0.3, ep_rew_mean ‚â• 0.1)\n",
    "- Professional visualization templates\n",
    "- Automated report generation (JSON + Markdown)\n",
    "- Results saved to `../results/phase2/`\n",
    "\n",
    "**üéØ TEAM A TODO:**\n",
    "1. Run Phase 2 OOS training (3 seeds √ó 50K steps)\n",
    "2. Update paths in Configuration section\n",
    "3. Customize visualization functions for your data structure\n",
    "4. Execute notebook after training completion\n",
    "5. Review generated reports and visualizations\n",
    "6. Share results with stakeholders for Phase 3 approval\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}