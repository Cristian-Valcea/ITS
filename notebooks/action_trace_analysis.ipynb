{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Trace Analysis - Stairways V3\n",
    "## Analyzing Agent Behavior Patterns During Good vs Bad Episodes\n",
    "\n",
    "This notebook analyzes agent behavior patterns to identify:\n",
    "- Position holding patterns\n",
    "- Trade timing and frequency\n",
    "- Reward hacking detection (flip-flops, position gaming)\n",
    "- P&L attribution to genuine market moves\n",
    "\n",
    "**Usage**: Run after Phase 1A freeze-early validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Action Trace Analysis - Stairways V3\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DIAGNOSTIC_PATH = Path('../diagnostic_runs/phase1a_freeze_early')\n",
    "RESULTS_PATH = Path('../diagnostic_runs/phase3_actions')\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Load action traces (generated during Phase 1A evaluation)\n",
    "try:\n",
    "    action_traces = pd.read_parquet(DIAGNOSTIC_PATH / 'action_traces.parquet')\n",
    "    print(f\"‚úÖ Loaded {len(action_traces)} action records\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Action traces not found. Run Phase 1A freeze-early tests first.\")\n",
    "    print(\"   Expected file: diagnostic_runs/phase1a_freeze_early/action_traces.parquet\")\n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    action_traces = pd.DataFrame({\n",
    "        'episode_id': np.repeat(range(100), 100),\n",
    "        'step': np.tile(range(100), 100),\n",
    "        'episode_reward': np.repeat(np.random.normal(0.2, 1.5, 100), 100),\n",
    "        'nvda_position': np.random.choice([-1, 0, 1], n_samples, p=[0.3, 0.4, 0.3]),\n",
    "        'msft_position': np.random.choice([-1, 0, 1], n_samples, p=[0.3, 0.4, 0.3]),\n",
    "        'step_pnl': np.random.normal(0, 50, n_samples),\n",
    "        'nvda_price': 485 + np.random.normal(0, 10, n_samples),\n",
    "        'msft_price': 412 + np.random.normal(0, 8, n_samples),\n",
    "        'action': np.random.randint(0, 5, n_samples),\n",
    "        'timestamp': pd.date_range('2024-02-01', periods=n_samples, freq='1min')\n",
    "    })\n",
    "    print(\"üìù Using sample data for demonstration\")\n",
    "\n",
    "print(f\"üìà Data shape: {action_traces.shape}\")\n",
    "print(f\"üìÖ Date range: {action_traces['timestamp'].min()} to {action_traces['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate good vs bad episodes based on reward thresholds\n",
    "GOOD_THRESHOLD = 0.5\n",
    "BAD_THRESHOLD = 0.0\n",
    "\n",
    "good_episodes = action_traces[action_traces['episode_reward'] > GOOD_THRESHOLD]\n",
    "bad_episodes = action_traces[action_traces['episode_reward'] < BAD_THRESHOLD]\n",
    "neutral_episodes = action_traces[\n",
    "    (action_traces['episode_reward'] >= BAD_THRESHOLD) & \n",
    "    (action_traces['episode_reward'] <= GOOD_THRESHOLD)\n",
    "]\n",
    "\n",
    "print(f\"üü¢ Good episodes (reward > {GOOD_THRESHOLD}): {len(good_episodes.groupby('episode_id'))} episodes\")\n",
    "print(f\"üî¥ Bad episodes (reward < {BAD_THRESHOLD}): {len(bad_episodes.groupby('episode_id'))} episodes\")\n",
    "print(f\"üü° Neutral episodes: {len(neutral_episodes.groupby('episode_id'))} episodes\")\n",
    "\n",
    "# Episode-level statistics\n",
    "episode_stats = action_traces.groupby('episode_id').agg({\n",
    "    'episode_reward': 'first',\n",
    "    'step': 'count',\n",
    "    'step_pnl': ['sum', 'std'],\n",
    "    'nvda_position': lambda x: (x.diff() != 0).sum(),  # Position changes\n",
    "    'msft_position': lambda x: (x.diff() != 0).sum()   # Position changes\n",
    "}).round(3)\n",
    "\n",
    "episode_stats.columns = ['reward', 'episode_length', 'total_pnl', 'pnl_volatility', 'nvda_changes', 'msft_changes']\n",
    "print(f\"\\nüìä Episode Statistics Summary:\")\n",
    "print(episode_stats.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Position Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_position_patterns(df, title, color='blue'):\n",
    "    \"\"\"Analyze position holding patterns for a given episode subset\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'{title} - Position Pattern Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Position Distribution\n",
    "    axes[0,0].hist(df['nvda_position'], bins=[-1.5, -0.5, 0.5, 1.5], alpha=0.7, \n",
    "                   label='NVDA', color='green', edgecolor='black')\n",
    "    axes[0,0].hist(df['msft_position'], bins=[-1.5, -0.5, 0.5, 1.5], alpha=0.7, \n",
    "                   label='MSFT', color='blue', edgecolor='black')\n",
    "    axes[0,0].set_title('Position Distribution')\n",
    "    axes[0,0].set_xlabel('Position (-1: Short, 0: Neutral, 1: Long)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].set_xticks([-1, 0, 1])\n",
    "    \n",
    "    # 2. Position Change Frequency (Flip-flop detection)\n",
    "    df_copy = df.copy().sort_values(['episode_id', 'step'])\n",
    "    df_copy['nvda_pos_change'] = df_copy.groupby('episode_id')['nvda_position'].diff().abs()\n",
    "    df_copy['msft_pos_change'] = df_copy.groupby('episode_id')['msft_position'].diff().abs()\n",
    "    \n",
    "    # Rolling average of position changes\n",
    "    window = min(50, len(df_copy) // 10)\n",
    "    if window > 1:\n",
    "        nvda_changes = df_copy['nvda_pos_change'].rolling(window, min_periods=1).mean()\n",
    "        msft_changes = df_copy['msft_pos_change'].rolling(window, min_periods=1).mean()\n",
    "        \n",
    "        axes[0,1].plot(nvda_changes, label='NVDA', color='green', alpha=0.8)\n",
    "        axes[0,1].plot(msft_changes, label='MSFT', color='blue', alpha=0.8)\n",
    "        axes[0,1].set_title(f'Position Change Frequency (Rolling {window}-step avg)')\n",
    "        axes[0,1].set_xlabel('Time Steps')\n",
    "        axes[0,1].set_ylabel('Avg Position Changes')\n",
    "        axes[0,1].legend()\n",
    "    \n",
    "    # 3. P&L vs NVDA Position\n",
    "    for pos in [-1, 0, 1]:\n",
    "        pos_data = df[df['nvda_position'] == pos]['step_pnl']\n",
    "        if len(pos_data) > 0:\n",
    "            axes[0,2].hist(pos_data, alpha=0.6, label=f'NVDA Pos {pos}', bins=20)\n",
    "    axes[0,2].set_title('P&L Distribution by NVDA Position')\n",
    "    axes[0,2].set_xlabel('Step P&L')\n",
    "    axes[0,2].set_ylabel('Frequency')\n",
    "    axes[0,2].legend()\n",
    "    \n",
    "    # 4. P&L vs MSFT Position\n",
    "    for pos in [-1, 0, 1]:\n",
    "        pos_data = df[df['msft_position'] == pos]['step_pnl']\n",
    "        if len(pos_data) > 0:\n",
    "            axes[1,0].hist(pos_data, alpha=0.6, label=f'MSFT Pos {pos}', bins=20)\n",
    "    axes[1,0].set_title('P&L Distribution by MSFT Position')\n",
    "    axes[1,0].set_xlabel('Step P&L')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # 5. Position vs Price Movement Correlation\n",
    "    if 'nvda_price' in df.columns:\n",
    "        df_copy['nvda_price_change'] = df_copy.groupby('episode_id')['nvda_price'].diff()\n",
    "        \n",
    "        # Scatter plot: Position vs Price Change\n",
    "        valid_data = df_copy.dropna(subset=['nvda_price_change'])\n",
    "        if len(valid_data) > 0:\n",
    "            axes[1,1].scatter(valid_data['nvda_position'], valid_data['nvda_price_change'], \n",
    "                            alpha=0.5, s=10, color='green')\n",
    "            axes[1,1].set_title('NVDA Position vs Price Change')\n",
    "            axes[1,1].set_xlabel('NVDA Position')\n",
    "            axes[1,1].set_ylabel('NVDA Price Change')\n",
    "            axes[1,1].set_xticks([-1, 0, 1])\n",
    "    \n",
    "    # 6. Action Distribution\n",
    "    if 'action' in df.columns:\n",
    "        action_counts = df['action'].value_counts().sort_index()\n",
    "        axes[1,2].bar(action_counts.index, action_counts.values, color=color, alpha=0.7)\n",
    "        axes[1,2].set_title('Action Distribution')\n",
    "        axes[1,2].set_xlabel('Action ID')\n",
    "        axes[1,2].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate analysis for good episodes\n",
    "if len(good_episodes) > 0:\n",
    "    good_fig = analyze_position_patterns(good_episodes, \"Good Episodes (Reward > 0.5)\", 'green')\n",
    "    good_fig.savefig(RESULTS_PATH / 'good_episodes_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No good episodes found for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate analysis for bad episodes\n",
    "if len(bad_episodes) > 0:\n",
    "    bad_fig = analyze_position_patterns(bad_episodes, \"Bad Episodes (Reward < 0)\", 'red')\n",
    "    bad_fig.savefig(RESULTS_PATH / 'bad_episodes_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No bad episodes found for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reward Hacking Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_reward_hacking(df, title):\n",
    "    \"\"\"Detect potential reward hacking patterns\"\"\"\n",
    "    print(f\"\\nüîç {title} - Reward Hacking Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Calculate flip-flop rates per episode\n",
    "    episode_flip_rates = []\n",
    "    \n",
    "    for episode_id in df['episode_id'].unique():\n",
    "        episode_data = df[df['episode_id'] == episode_id].sort_values('step')\n",
    "        \n",
    "        if len(episode_data) > 1:\n",
    "            nvda_flips = (episode_data['nvda_position'].diff() != 0).sum()\n",
    "            msft_flips = (episode_data['msft_position'].diff() != 0).sum()\n",
    "            total_steps = len(episode_data)\n",
    "            \n",
    "            flip_rate = (nvda_flips + msft_flips) / (2 * total_steps)  # Normalize by positions and steps\n",
    "            episode_flip_rates.append({\n",
    "                'episode_id': episode_id,\n",
    "                'flip_rate': flip_rate,\n",
    "                'nvda_flips': nvda_flips,\n",
    "                'msft_flips': msft_flips,\n",
    "                'total_steps': total_steps,\n",
    "                'episode_reward': episode_data['episode_reward'].iloc[0]\n",
    "            })\n",
    "    \n",
    "    flip_df = pd.DataFrame(episode_flip_rates)\n",
    "    \n",
    "    if len(flip_df) > 0:\n",
    "        # Statistics\n",
    "        avg_flip_rate = flip_df['flip_rate'].mean()\n",
    "        high_flip_episodes = flip_df[flip_df['flip_rate'] > 0.1]  # More than 10% flip rate\n",
    "        \n",
    "        print(f\"üìä Average flip rate: {avg_flip_rate:.3f}\")\n",
    "        print(f\"‚ö†Ô∏è  High flip-rate episodes (>10%): {len(high_flip_episodes)}\")\n",
    "        \n",
    "        if len(high_flip_episodes) > 0:\n",
    "            print(f\"üö® Potential reward hacking detected in {len(high_flip_episodes)} episodes\")\n",
    "            print(\"   Top flip-rate episodes:\")\n",
    "            top_flippers = high_flip_episodes.nlargest(5, 'flip_rate')\n",
    "            for _, row in top_flippers.iterrows():\n",
    "                print(f\"   Episode {row['episode_id']}: {row['flip_rate']:.3f} flip rate, reward: {row['episode_reward']:.3f}\")\n",
    "        else:\n",
    "            print(\"‚úÖ No obvious flip-flop patterns detected\")\n",
    "        \n",
    "        # Visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Flip rate distribution\n",
    "        axes[0].hist(flip_df['flip_rate'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[0].axvline(avg_flip_rate, color='red', linestyle='--', label=f'Mean: {avg_flip_rate:.3f}')\n",
    "        axes[0].axvline(0.1, color='orange', linestyle='--', label='High flip threshold (0.1)')\n",
    "        axes[0].set_title(f'{title}: Flip Rate Distribution')\n",
    "        axes[0].set_xlabel('Flip Rate (position changes per step)')\n",
    "        axes[0].set_ylabel('Number of Episodes')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Flip rate vs reward correlation\n",
    "        axes[1].scatter(flip_df['flip_rate'], flip_df['episode_reward'], alpha=0.6)\n",
    "        axes[1].set_title(f'{title}: Flip Rate vs Episode Reward')\n",
    "        axes[1].set_xlabel('Flip Rate')\n",
    "        axes[1].set_ylabel('Episode Reward')\n",
    "        \n",
    "        # Add correlation coefficient\n",
    "        correlation = flip_df['flip_rate'].corr(flip_df['episode_reward'])\n",
    "        axes[1].text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                    transform=axes[1].transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_PATH / f'{title.lower().replace(\" \", \"_\")}_flip_analysis.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return flip_df\n",
    "    else:\n",
    "        print(\"‚ùå No episodes found for analysis\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Analyze good and bad episodes for reward hacking\n",
    "if len(good_episodes) > 0:\n",
    "    good_flip_analysis = detect_reward_hacking(good_episodes, \"Good Episodes\")\n",
    "\n",
    "if len(bad_episodes) > 0:\n",
    "    bad_flip_analysis = detect_reward_hacking(bad_episodes, \"Bad Episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trade Timeline Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trade_timeline(df, title, max_episodes=5):\n",
    "    \"\"\"Analyze trade timelines for selected episodes\"\"\"\n",
    "    print(f\"\\nüìà {title} - Trade Timeline Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Select representative episodes\n",
    "    episode_rewards = df.groupby('episode_id')['episode_reward'].first().sort_values(ascending=False)\n",
    "    selected_episodes = episode_rewards.head(max_episodes).index\n",
    "    \n",
    "    fig, axes = plt.subplots(max_episodes, 1, figsize=(15, 3*max_episodes))\n",
    "    if max_episodes == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, episode_id in enumerate(selected_episodes):\n",
    "        episode_data = df[df['episode_id'] == episode_id].sort_values('step')\n",
    "        \n",
    "        if len(episode_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Create timeline plot\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot positions\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "        # P&L line\n",
    "        cumulative_pnl = episode_data['step_pnl'].cumsum()\n",
    "        ax.plot(episode_data['step'], cumulative_pnl, 'b-', linewidth=2, label='Cumulative P&L')\n",
    "        ax.set_ylabel('Cumulative P&L', color='b')\n",
    "        ax.tick_params(axis='y', labelcolor='b')\n",
    "        \n",
    "        # Position bars\n",
    "        ax2.bar(episode_data['step'], episode_data['nvda_position'], \n",
    "               alpha=0.3, color='green', label='NVDA Position', width=0.8)\n",
    "        ax2.bar(episode_data['step'], episode_data['msft_position'], \n",
    "               alpha=0.3, color='blue', label='MSFT Position', width=0.8, bottom=episode_data['nvda_position'])\n",
    "        ax2.set_ylabel('Position', color='g')\n",
    "        ax2.tick_params(axis='y', labelcolor='g')\n",
    "        ax2.set_ylim(-2.5, 2.5)\n",
    "        \n",
    "        # Title and labels\n",
    "        episode_reward = episode_data['episode_reward'].iloc[0]\n",
    "        final_pnl = cumulative_pnl.iloc[-1]\n",
    "        ax.set_title(f'Episode {episode_id}: Reward={episode_reward:.3f}, Final P&L={final_pnl:.2f}')\n",
    "        ax.set_xlabel('Step')\n",
    "        \n",
    "        # Add legends\n",
    "        ax.legend(loc='upper left')\n",
    "        ax2.legend(loc='upper right')\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_PATH / f'{title.lower().replace(\" \", \"_\")}_timeline.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nüìä Timeline Analysis Summary:\")\n",
    "    for episode_id in selected_episodes:\n",
    "        episode_data = df[df['episode_id'] == episode_id]\n",
    "        if len(episode_data) > 0:\n",
    "            reward = episode_data['episode_reward'].iloc[0]\n",
    "            total_pnl = episode_data['step_pnl'].sum()\n",
    "            avg_position = (abs(episode_data['nvda_position']).mean() + abs(episode_data['msft_position']).mean()) / 2\n",
    "            print(f\"  Episode {episode_id}: Reward={reward:.3f}, Total P&L={total_pnl:.2f}, Avg |Position|={avg_position:.3f}\")\n",
    "\n",
    "# Analyze timelines for good and bad episodes\n",
    "if len(good_episodes) > 0:\n",
    "    analyze_trade_timeline(good_episodes, \"Good Episodes\", max_episodes=3)\n",
    "\n",
    "if len(bad_episodes) > 0:\n",
    "    analyze_trade_timeline(bad_episodes, \"Bad Episodes\", max_episodes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Market Alignment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_market_alignment(df, title):\n",
    "    \"\"\"Analyze if trades align with actual market movements\"\"\"\n",
    "    print(f\"\\nüéØ {title} - Market Alignment Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if 'nvda_price' not in df.columns or 'msft_price' not in df.columns:\n",
    "        print(\"‚ùå Price data not available for market alignment analysis\")\n",
    "        return\n",
    "    \n",
    "    # Calculate price changes and position alignment\n",
    "    df_analysis = df.copy().sort_values(['episode_id', 'step'])\n",
    "    \n",
    "    # Price changes\n",
    "    df_analysis['nvda_price_change'] = df_analysis.groupby('episode_id')['nvda_price'].diff()\n",
    "    df_analysis['msft_price_change'] = df_analysis.groupby('episode_id')['msft_price'].diff()\n",
    "    \n",
    "    # Position-price alignment (positive when position and price change have same sign)\n",
    "    df_analysis['nvda_alignment'] = df_analysis['nvda_position'] * df_analysis['nvda_price_change']\n",
    "    df_analysis['msft_alignment'] = df_analysis['msft_position'] * df_analysis['msft_price_change']\n",
    "    \n",
    "    # Remove NaN values\n",
    "    df_clean = df_analysis.dropna(subset=['nvda_price_change', 'msft_price_change'])\n",
    "    \n",
    "    if len(df_clean) == 0:\n",
    "        print(\"‚ùå No valid price change data available\")\n",
    "        return\n",
    "    \n",
    "    # Calculate alignment statistics\n",
    "    nvda_positive_alignment = (df_clean['nvda_alignment'] > 0).mean()\n",
    "    msft_positive_alignment = (df_clean['msft_alignment'] > 0).mean()\n",
    "    \n",
    "    print(f\"üìä NVDA Position-Price Alignment: {nvda_positive_alignment:.3f} ({nvda_positive_alignment*100:.1f}% positive)\")\n",
    "    print(f\"üìä MSFT Position-Price Alignment: {msft_positive_alignment:.3f} ({msft_positive_alignment*100:.1f}% positive)\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if nvda_positive_alignment > 0.6:\n",
    "        print(\"‚úÖ NVDA: Good market alignment - positions generally follow price direction\")\n",
    "    elif nvda_positive_alignment < 0.4:\n",
    "        print(\"‚ö†Ô∏è NVDA: Poor market alignment - positions often oppose price direction\")\n",
    "    else:\n",
    "        print(\"üü° NVDA: Neutral market alignment\")\n",
    "        \n",
    "    if msft_positive_alignment > 0.6:\n",
    "        print(\"‚úÖ MSFT: Good market alignment - positions generally follow price direction\")\n",
    "    elif msft_positive_alignment < 0.4:\n",
    "        print(\"‚ö†Ô∏è MSFT: Poor market alignment - positions often oppose price direction\")\n",
    "    else:\n",
    "        print(\"üü° MSFT: Neutral market alignment\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # NVDA alignment scatter\n",
    "    axes[0,0].scatter(df_clean['nvda_price_change'], df_clean['nvda_position'], \n",
    "                     alpha=0.5, s=10, c=df_clean['nvda_alignment'], cmap='RdYlGn')\n",
    "    axes[0,0].set_title('NVDA: Position vs Price Change')\n",
    "    axes[0,0].set_xlabel('NVDA Price Change')\n",
    "    axes[0,0].set_ylabel('NVDA Position')\n",
    "    axes[0,0].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[0,0].axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # MSFT alignment scatter\n",
    "    axes[0,1].scatter(df_clean['msft_price_change'], df_clean['msft_position'], \n",
    "                     alpha=0.5, s=10, c=df_clean['msft_alignment'], cmap='RdYlGn')\n",
    "    axes[0,1].set_title('MSFT: Position vs Price Change')\n",
    "    axes[0,1].set_xlabel('MSFT Price Change')\n",
    "    axes[0,1].set_ylabel('MSFT Position')\n",
    "    axes[0,1].axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    axes[0,1].axvline(x=0, color='k', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Alignment histograms\n",
    "    axes[1,0].hist(df_clean['nvda_alignment'], bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1,0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[1,0].set_title('NVDA Alignment Distribution')\n",
    "    axes[1,0].set_xlabel('Position √ó Price Change')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    \n",
    "    axes[1,1].hist(df_clean['msft_alignment'], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[1,1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "    axes[1,1].set_title('MSFT Alignment Distribution')\n",
    "    axes[1,1].set_xlabel('Position √ó Price Change')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_PATH / f'{title.lower().replace(\" \", \"_\")}_market_alignment.png', \n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'nvda_alignment': nvda_positive_alignment,\n",
    "        'msft_alignment': msft_positive_alignment\n",
    "    }\n",
    "\n",
    "# Analyze market alignment for good and bad episodes\n",
    "alignment_results = {}\n",
    "\n",
    "if len(good_episodes) > 0:\n",
    "    alignment_results['good'] = analyze_market_alignment(good_episodes, \"Good Episodes\")\n",
    "\n",
    "if len(bad_episodes) > 0:\n",
    "    alignment_results['bad'] = analyze_market_alignment(bad_episodes, \"Bad Episodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report():\n",
    "    \"\"\"Generate comprehensive summary report\"\"\"\n",
    "    print(\"\\nüìã ACTION TRACE ANALYSIS - SUMMARY REPORT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Episode statistics\n",
    "    total_episodes = len(action_traces['episode_id'].unique())\n",
    "    good_count = len(good_episodes['episode_id'].unique()) if len(good_episodes) > 0 else 0\n",
    "    bad_count = len(bad_episodes['episode_id'].unique()) if len(bad_episodes) > 0 else 0\n",
    "    \n",
    "    print(f\"üìä EPISODE BREAKDOWN:\")\n",
    "    print(f\"   Total Episodes: {total_episodes}\")\n",
    "    print(f\"   Good Episodes (reward > 0.5): {good_count} ({good_count/total_episodes*100:.1f}%)\")\n",
    "    print(f\"   Bad Episodes (reward < 0): {bad_count} ({bad_count/total_episodes*100:.1f}%)\")\n",
    "    \n",
    "    # Reward hacking assessment\n",
    "    print(f\"\\nüîç REWARD HACKING ASSESSMENT:\")\n",
    "    \n",
    "    if len(good_episodes) > 0 and 'good_flip_analysis' in locals():\n",
    "        good_high_flip = len(good_flip_analysis[good_flip_analysis['flip_rate'] > 0.1])\n",
    "        good_avg_flip = good_flip_analysis['flip_rate'].mean()\n",
    "        print(f\"   Good Episodes - Avg flip rate: {good_avg_flip:.3f}, High flip episodes: {good_high_flip}\")\n",
    "        \n",
    "        if good_high_flip > good_count * 0.2:  # More than 20% have high flip rates\n",
    "            print(f\"   üö® CONCERN: {good_high_flip} good episodes show high flip rates (potential reward hacking)\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Good episodes show reasonable trading patterns\")\n",
    "    \n",
    "    if len(bad_episodes) > 0 and 'bad_flip_analysis' in locals():\n",
    "        bad_high_flip = len(bad_flip_analysis[bad_flip_analysis['flip_rate'] > 0.1])\n",
    "        bad_avg_flip = bad_flip_analysis['flip_rate'].mean()\n",
    "        print(f\"   Bad Episodes - Avg flip rate: {bad_avg_flip:.3f}, High flip episodes: {bad_high_flip}\")\n",
    "    \n",
    "    # Market alignment assessment\n",
    "    print(f\"\\nüéØ MARKET ALIGNMENT ASSESSMENT:\")\n",
    "    \n",
    "    if 'good' in alignment_results:\n",
    "        good_nvda = alignment_results['good']['nvda_alignment']\n",
    "        good_msft = alignment_results['good']['msft_alignment']\n",
    "        print(f\"   Good Episodes - NVDA alignment: {good_nvda:.3f}, MSFT alignment: {good_msft:.3f}\")\n",
    "        \n",
    "        if good_nvda > 0.6 and good_msft > 0.6:\n",
    "            print(f\"   ‚úÖ Good episodes show strong market alignment (genuine trading)\")\n",
    "        elif good_nvda < 0.4 or good_msft < 0.4:\n",
    "            print(f\"   ‚ö†Ô∏è Good episodes show poor market alignment (potential issues)\")\n",
    "        else:\n",
    "            print(f\"   üü° Good episodes show mixed market alignment\")\n",
    "    \n",
    "    if 'bad' in alignment_results:\n",
    "        bad_nvda = alignment_results['bad']['nvda_alignment']\n",
    "        bad_msft = alignment_results['bad']['msft_alignment']\n",
    "        print(f\"   Bad Episodes - NVDA alignment: {bad_nvda:.3f}, MSFT alignment: {bad_msft:.3f}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    print(f\"\\nüéØ OVERALL ASSESSMENT:\")\n",
    "    \n",
    "    concerns = []\n",
    "    positives = []\n",
    "    \n",
    "    # Check for major issues\n",
    "    if good_count < total_episodes * 0.1:\n",
    "        concerns.append(\"Very few good episodes - potential fundamental issues\")\n",
    "    \n",
    "    if len(good_episodes) > 0 and 'good_flip_analysis' in locals():\n",
    "        if len(good_flip_analysis[good_flip_analysis['flip_rate'] > 0.1]) > good_count * 0.2:\n",
    "            concerns.append(\"High flip rates in good episodes - potential reward hacking\")\n",
    "        else:\n",
    "            positives.append(\"Good episodes show reasonable trading patterns\")\n",
    "    \n",
    "    if 'good' in alignment_results:\n",
    "        if alignment_results['good']['nvda_alignment'] > 0.6 and alignment_results['good']['msft_alignment'] > 0.6:\n",
    "            positives.append(\"Strong market alignment in good episodes\")\n",
    "        elif alignment_results['good']['nvda_alignment'] < 0.4 or alignment_results['good']['msft_alignment'] < 0.4:\n",
    "            concerns.append(\"Poor market alignment in good episodes\")\n",
    "    \n",
    "    if concerns:\n",
    "        print(f\"   üö® CONCERNS IDENTIFIED:\")\n",
    "        for concern in concerns:\n",
    "            print(f\"      - {concern}\")\n",
    "    \n",
    "    if positives:\n",
    "        print(f\"   ‚úÖ POSITIVE FINDINGS:\")\n",
    "        for positive in positives:\n",
    "            print(f\"      - {positive}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    \n",
    "    if len(concerns) == 0:\n",
    "        print(f\"   ‚úÖ No major issues detected - proceed with Phase 2 temporal validation\")\n",
    "    elif \"reward hacking\" in str(concerns):\n",
    "        print(f\"   üîß Address reward system - implement stronger anti-gaming measures\")\n",
    "    elif \"market alignment\" in str(concerns):\n",
    "        print(f\"   üîß Review position logic - ensure trades align with market movements\")\n",
    "    else:\n",
    "        print(f\"   üîß Investigate fundamental training issues before proceeding\")\n",
    "    \n",
    "    # Save summary to file\n",
    "    summary_text = f\"\"\"\n",
    "ACTION TRACE ANALYSIS SUMMARY\n",
    "Generated: {pd.Timestamp.now()}\n",
    "\n",
    "EPISODE BREAKDOWN:\n",
    "- Total Episodes: {total_episodes}\n",
    "- Good Episodes: {good_count} ({good_count/total_episodes*100:.1f}%)\n",
    "- Bad Episodes: {bad_count} ({bad_count/total_episodes*100:.1f}%)\n",
    "\n",
    "CONCERNS: {len(concerns)}\n",
    "{chr(10).join([f'- {c}' for c in concerns])}\n",
    "\n",
    "POSITIVES: {len(positives)}\n",
    "{chr(10).join([f'- {p}' for p in positives])}\n",
    "\n",
    "FILES GENERATED:\n",
    "- good_episodes_analysis.png\n",
    "- bad_episodes_analysis.png\n",
    "- good_episodes_flip_analysis.png\n",
    "- bad_episodes_flip_analysis.png\n",
    "- good_episodes_timeline.png\n",
    "- bad_episodes_timeline.png\n",
    "- good_episodes_market_alignment.png\n",
    "- bad_episodes_market_alignment.png\n",
    "\"\"\"\n",
    "    \n",
    "    with open(RESULTS_PATH / 'action_trace_summary.txt', 'w') as f:\n",
    "        f.write(summary_text)\n",
    "    \n",
    "    print(f\"\\nüìÅ Results saved to: {RESULTS_PATH}\")\n",
    "    print(f\"üìÑ Summary report: {RESULTS_PATH / 'action_trace_summary.txt'}\")\n",
    "\n",
    "# Generate the summary report\n",
    "generate_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "Based on this analysis:\n",
    "\n",
    "1. **If no major issues detected**: Proceed with Phase 2 temporal validation\n",
    "2. **If reward hacking detected**: Implement stronger anti-gaming measures in reward system\n",
    "3. **If poor market alignment**: Review position logic and ensure trades align with market movements\n",
    "4. **If fundamental issues**: Investigate training process before proceeding\n",
    "\n",
    "**Files generated in `diagnostic_runs/phase3_actions/`:**\n",
    "- `good_episodes_analysis.png` - Position patterns for good episodes\n",
    "- `bad_episodes_analysis.png` - Position patterns for bad episodes  \n",
    "- `*_flip_analysis.png` - Reward hacking detection charts\n",
    "- `*_timeline.png` - Trade timeline visualizations\n",
    "- `*_market_alignment.png` - Market alignment analysis\n",
    "- `action_trace_summary.txt` - Text summary of findings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}